{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","celltoolbar":"Slideshow","colab":{"name":"EVAGAN_CC.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0_CBy18urmEJ"},"source":["<a id=\"CGAN\"><h1>Import Header</h1></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVT9VNymvXmJ","executionInfo":{"status":"ok","timestamp":1627465220082,"user_tz":-300,"elapsed":653,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"cff7c774-0d94-40be-aa54-c95788750edd"},"source":["from google.colab import drive \n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/PhD/Development/code/Current/EVAGAN"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v6FKoBgiv8Nq"},"source":["# !pip install smote_variants"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"iCYI2W39rmEQ"},"source":["import importlib\n","import header\n","\n","importlib.reload(header) # For reloading after making changes\n","from header import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"aQkaphklFIYW"},"source":["<a id=\"CGAN\"><h1>Select GAN and Dataset and Flags</h1></a>"]},{"cell_type":"code","metadata":{"id":"9pihuGPGrmEX"},"source":["# GAN_type = 'GAN'\n","# GAN_type = 'CGAN'\n","# GAN_type = 'WGAN'\n","# GAN_type = 'WCGAN'\n","GAN_type = 'EVAGAN_CC'\n","# GAN_type = 'ACGAN_CV'\n","# GAN_type = 'EVAGAN_CV'\n","\n","\n","\n","\n","# DATA_SET = 'ISCX-2014'\n","DATA_SET = 'CIC-2017'\n","# DATA_SET = 'CIC-2018'\n","# DATA_SET = 'UNSW_BotIoT'\n","\n","\n","# DATA_SET = 'Drebin'\n","\n","# DATA_SET = 'Darknet'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2eQzRLgcrmEZ"},"source":["<a id=\"GPU Settings\"><h2>Set Flags</h2></a>"]},{"cell_type":"code","metadata":{"id":"kcmqEWmGrmEb"},"source":["begin_from_start = 1\n","take_chunk = 0\n","required_epochs = 150\n","\n","DISPLAY_FEATURES = 0\n","EVALUATION_PARAMETER = 'Accuracy'\n","SAVE_ONLY_BOT_DATA = 0\n","USE_KMEANS_FOR_CLASSIFICATION = 1\n","\n","BALANCE_THE_DATASET = 1\n","\n","labels =[]\n","\n","USE_ONLY_TRAIN_SET = 1\n","\n","USE_ALL_CLASSIFIERS = 0\n","\n","ACCU_EVAL_TEST = 0\n","RCL_EVAL_TEST = 0\n","\n","VISUAL_TEST_OVERLAPPING = 1\n","\n","CSV_ONE_BOT = 0\n","\n","VIEW_ALL_BOTS = 0\n","\n","CTU_NERIS = 0\n","\n","SINGLE_WEIGHT_CLASSIFIER_TEST_C2ST = 0\n","SINGLE_WEIGHT_CLASSIFIER_TEST_PROPOSED_METHODOLOGY = 0\n","\n","C2ST_BLACK_BOX_TEST = 0\n","BOTSHOT_BLACK_BOX_TEST = 0\n","\n","C2ST_BLACK_BOX_TEST_AFTER_GAN_TRAINING = 0\n","BOTSHOT_BLACK_BOX_TEST_AFTER_GAN_TRAINING = 0\n","\n","GENERATE_OTHERS_DATA = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HmNvuPg-rmEd"},"source":["<a id=\"CGAN\"><h1>Set Paths</h1></a>"]},{"cell_type":"code","metadata":{"id":"Dy4M7qEWrmEe"},"source":["MAIN_CODE_PATH = os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrizUpKsYxel"},"source":["DATA_SET_PATH = MAIN_CODE_PATH + '/Dataset/' +  DATA_SET + '/'\n","CACHE_PATH = MAIN_CODE_PATH + '/cache/' + GAN_type + '/'\n","FIGS_PATH = MAIN_CODE_PATH  + '/figs/' + GAN_type + '/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"QVoXeZLNrmEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465224990,"user_tz":-300,"elapsed":101,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"a93736d1-ae5a-43f3-ea1e-576ffa1b77cb"},"source":["print(DATA_SET_PATH)\n","print(CACHE_PATH)\n","print(FIGS_PATH)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/PhD/Development/code/Current/EVAGAN/Dataset/CIC-2017/\n","/content/drive/My Drive/PhD/Development/code/Current/EVAGAN/cache/EVAGAN_CC/\n","/content/drive/My Drive/PhD/Development/code/Current/EVAGAN/figs/EVAGAN_CC/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ZYuHUIZrmEm"},"source":["<a id=\"GPU Settings\"><h2>Check Available GPUs</h2></a>"]},{"cell_type":"code","metadata":{"id":"5H9Fx4xvrmEo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465224992,"user_tz":-300,"elapsed":97,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"f752f5b4-01d6-486d-d1bb-5f81c68e552f"},"source":["import tensorflow as tf\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Num GPUs Available:  1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MPDAPhRdrmEp"},"source":["<a id=\"GPU Settings\"><h2>Import Dataset</h2></a>"]},{"cell_type":"code","metadata":{"id":"1RwAfH0HrmEq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465224995,"user_tz":-300,"elapsed":85,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"509aec8e-6d06-4745-e473-4c30f36f1b4d"},"source":["%cd $DATA_SET_PATH\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/PhD/Development/code/Current/EVAGAN/Dataset/CIC-2017\n"," best_losses.csv\t\t\t  GAN_2contour.eps\n"," CGAN_data_frame_of_bots_0.csv\t\t  GAN_4contour.eps\n"," CGAN_data_frame_of_bots_10.csv\t\t  GAN_6contour.eps\n"," CGAN_data_frame_of_bots_2.csv\t\t  GAN_8contour.eps\n"," CGAN_data_frame_of_bots_4.csv\t\t  GAN_data_frame_of_bots_0.csv\n"," CGAN_data_frame_of_bots_6.csv\t\t  GAN_data_frame_of_bots_10.csv\n"," CGAN_data_frame_of_bots_8.csv\t\t  GAN_data_frame_of_bots_2.csv\n"," CGAN_losses.csv\t\t\t  GAN_data_frame_of_bots_4.csv\n"," CIC_Friday_bot.csv\t\t\t  GAN_data_frame_of_bots_6.csv\n","'CIC_Friday_bot.csv_(Preprocessed).csv'   GAN_data_frame_of_bots_8.csv\n"," GAN_0contour.eps\t\t\t  GANlosses.csv\n"," GAN_10contour.eps\t\t\t  shuffled_T_B.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"SgA2CVe5rmEr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465248260,"user_tz":-300,"elapsed":23316,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"1b8b0a3c-5546-4769-c3f2-df1a8878a16c"},"source":["if begin_from_start:        \n","\n","    if DATA_SET == 'ISCX-2014':\n","        training_data = prepare_ISCX_2014_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'ISCX_Botnet-Training.pcap_Flow.csv')\n","        testing_data = prepare_ISCX_2014_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'ISCX_Botnet-Testing.pcap_Flow.csv') \n","    \n","    elif DATA_SET == 'CIC-2017':\n","        training_data = prepare_cic_2017_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'CIC_Friday_bot.csv')\n","        testing_data = prepare_cic_2017_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'CIC_Friday_bot.csv')\n","        \n","    elif DATA_SET == 'CIC-2018':\n","        training_data = prepare_cic_2018_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv')\n","        testing_data = prepare_cic_2018_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv')\n","        \n","    elif DATA_SET == 'UNSW_BotIoT':\n","        training_data = prepare_UNSW_IoT(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'UNSW_2018_IoT_Botnet_Final_10_best_Training.csv')\n","        testing_data = prepare_UNSW_IoT(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'UNSW_2018_IoT_Botnet_Final_10_best_Testing.csv')\n","        \n","    elif DATA_SET == 'Darknet':\n","        training_data = prepare_DARKNET_2020_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'Darknet.csv')\n","        testing_data = prepare_DARKNET_2020_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'Darknet.csv')\n","        \n","        \n","\n","    print('Dataset preprocessed: ' + DATA_SET)\n","    \n","else:\n","\n","    if DATA_SET == 'ISCX-2014':\n","        INPUT_TRAINING_FILE_NAME = r'ISCX_Botnet-Training.pcap_Flow.csv_VIRUT'\n","        INPUT_TESTING_FILE_NAME = r'ISCX_Botnet-Testing.pcap_Flow.csv_VIRUT'\n","        \n","    elif DATA_SET == 'CIC-2017':\n","        INPUT_TRAINING_FILE_NAME = r'CIC_Friday_bot.csv'\n","        INPUT_TESTING_FILE_NAME = r'CIC_Friday_bot.csv'\n","        \n","    elif DATA_SET == 'CIC-2018':\n","        INPUT_TRAINING_FILE_NAME = r'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv'\n","        INPUT_TESTING_FILE_NAME = r'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv'\n","        \n","    elif DATA_SET == 'BoT-IoT':\n","        INPUT_TRAINING_FILE_NAME = r'UNSW_2018_IoT_Botnet_Final_10_best_Training.csv'\n","        INPUT_TESTING_FILE_NAME = r'UNSW_2018_IoT_Botnet_Final_10_best_Testing.csv'\n","        \n","    elif DATA_SET == 'Drebin':\n","        INPUT_TRAINING_FILE_NAME = r'Drebin_API_Dataset.csv'\n","        INPUT_TESTING_FILE_NAME = r'Drebin_API_Dataset.csv'\n","        \n","    elif DATA_SET == 'Darknet':\n","        INPUT_TRAINING_FILE_NAME = r'Darknet.csv'\n","        INPUT_TESTING_FILE_NAME = r'Darknet.csv'\n","\n","    training_data = pd.read_csv (INPUT_TRAINING_FILE_NAME + '_(Preprocessed).csv', low_memory=False)\n","    training_data= training_data.drop(['Unnamed: 0'], axis=1)\n","    \n","    testing_data = pd.read_csv (INPUT_TESTING_FILE_NAME + '_(Preprocessed).csv', low_memory=False)\n","    testing_data= testing_data.drop(['Unnamed: 0'], axis=1) \n","    \n","    print('Dataset Imported: ' + DATA_SET)\n","    print('Training set: '+ str(training_data.shape))\n","    print('Testng set: '+ str(training_data.shape))\n","    \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing File: CIC_Friday_bot.csv DATA shape: (191033, 78)\n","Before Preprocesing: Total: (191033, 78)\n","Before Preprocesing: Normal: (189067, 78)\n","Before Preprocesing: Bots: (1966, 78)\n","Data Shape before droping NULL and INF values: \n","(191033, 78)\n","Data Shape after droping NULL and INF values: \n","(190911, 78)\n","data_df after removing Label column\n","(190911, 77)\n"," Data Columns after converting to Float\n","       FlowDuration  TotalFwdPackets  ...       IdleMax       IdleMin\n","count  1.909020e+05     190911.00000  ...  1.909110e+05  1.909110e+05\n","mean   1.165298e+07         13.83442  ...  4.050751e+06  3.748148e+06\n","std    3.070986e+07       1098.10619  ...  1.424541e+07  1.370882e+07\n","min    1.000000e+00          1.00000  ...  0.000000e+00  0.000000e+00\n","25%    1.950000e+02          2.00000  ...  0.000000e+00  0.000000e+00\n","50%    3.113100e+04          2.00000  ...  0.000000e+00  0.000000e+00\n","75%    4.129102e+05          4.00000  ...  0.000000e+00  0.000000e+00\n","max    1.200000e+08     207964.00000  ...  1.200000e+08  1.200000e+08\n","\n","[8 rows x 77 columns]\n","INF values before removing: Int64Index([], dtype='int64')\n","INF values removed and Data reindexed\n","Data before removing std = 0 columns\n","(190911, 77)\n","(190911, 78)\n","Data after removing std = 0 columns\n","(190911, 68)\n","INF values: 214460\n","Any Left over INF values: Int64Index([], dtype='int64')\n"," Data Columns after removing Flow ID: Index(['FlowDuration', 'TotalFwdPackets', 'TotalBackwardPackets',\n","       'TotalLengthofFwdPackets', 'TotalLengthofBwdPackets',\n","       'FwdPacketLengthMax', 'FwdPacketLengthMin', 'FwdPacketLengthMean',\n","       'FwdPacketLengthStd', 'BwdPacketLengthMax', 'BwdPacketLengthMin',\n","       'BwdPacketLengthMean', 'BwdPacketLengthStd', 'FlowBytes/s',\n","       'FlowPackets/s', 'FlowIATMean', 'FlowIATStd', 'FlowIATMax',\n","       'FlowIATMin', 'FwdIATTotal', 'FwdIATMean', 'FwdIATStd', 'FwdIATMax',\n","       'FwdIATMin', 'BwdIATTotal', 'BwdIATMean', 'BwdIATStd', 'BwdIATMax',\n","       'BwdIATMin', 'FwdPSHFlags', 'FwdHeaderLength', 'BwdHeaderLength',\n","       'FwdPackets/s', 'BwdPackets/s', 'MinPacketLength', 'MaxPacketLength',\n","       'PacketLengthMean', 'PacketLengthStd', 'PacketLengthVariance',\n","       'FINFlagCount', 'SYNFlagCount', 'RSTFlagCount', 'PSHFlagCount',\n","       'ACKFlagCount', 'URGFlagCount', 'ECEFlagCount', 'Down/UpRatio',\n","       'AveragePacketSize', 'AvgFwdSegmentSize', 'AvgBwdSegmentSize',\n","       'FwdHeaderLength.1', 'SubflowFwdPackets', 'SubflowFwdBytes',\n","       'SubflowBwdPackets', 'SubflowBwdBytes', 'Init_Win_bytes_forward',\n","       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n","       'ActiveMean', 'ActiveStd', 'ActiveMax', 'ActiveMin', 'IdleMean',\n","       'IdleStd', 'IdleMax', 'IdleMin', 'Label'],\n","      dtype='object')\n","Data Shape before droping NULL and INF values: \n","(190911, 68)\n","Data Shape before droping NULL and INF values: \n","(72330, 68)\n","After Preprocesing: Total: (72330, 68)\n","After Preprocesing: Normal: (70374, 68)\n","After Preprocesing: Bots: (1956, 68)\n","File: CIC_Friday_bot.csv_(Preprocessed).csv Saving ...\n","File: CIC_Friday_bot.csv_(Preprocessed).csv saved to directory\n","Processing File: CIC_Friday_bot.csv DATA shape: (191033, 78)\n","Before Preprocesing: Total: (191033, 78)\n","Before Preprocesing: Normal: (189067, 78)\n","Before Preprocesing: Bots: (1966, 78)\n","Data Shape before droping NULL and INF values: \n","(191033, 78)\n","Data Shape after droping NULL and INF values: \n","(190911, 78)\n","data_df after removing Label column\n","(190911, 77)\n"," Data Columns after converting to Float\n","       FlowDuration  TotalFwdPackets  ...       IdleMax       IdleMin\n","count  1.909020e+05     190911.00000  ...  1.909110e+05  1.909110e+05\n","mean   1.165298e+07         13.83442  ...  4.050751e+06  3.748148e+06\n","std    3.070986e+07       1098.10619  ...  1.424541e+07  1.370882e+07\n","min    1.000000e+00          1.00000  ...  0.000000e+00  0.000000e+00\n","25%    1.950000e+02          2.00000  ...  0.000000e+00  0.000000e+00\n","50%    3.113100e+04          2.00000  ...  0.000000e+00  0.000000e+00\n","75%    4.129102e+05          4.00000  ...  0.000000e+00  0.000000e+00\n","max    1.200000e+08     207964.00000  ...  1.200000e+08  1.200000e+08\n","\n","[8 rows x 77 columns]\n","INF values before removing: Int64Index([], dtype='int64')\n","INF values removed and Data reindexed\n","Data before removing std = 0 columns\n","(190911, 77)\n","(190911, 78)\n","Data after removing std = 0 columns\n","(190911, 68)\n","INF values: 214460\n","Any Left over INF values: Int64Index([], dtype='int64')\n"," Data Columns after removing Flow ID: Index(['FlowDuration', 'TotalFwdPackets', 'TotalBackwardPackets',\n","       'TotalLengthofFwdPackets', 'TotalLengthofBwdPackets',\n","       'FwdPacketLengthMax', 'FwdPacketLengthMin', 'FwdPacketLengthMean',\n","       'FwdPacketLengthStd', 'BwdPacketLengthMax', 'BwdPacketLengthMin',\n","       'BwdPacketLengthMean', 'BwdPacketLengthStd', 'FlowBytes/s',\n","       'FlowPackets/s', 'FlowIATMean', 'FlowIATStd', 'FlowIATMax',\n","       'FlowIATMin', 'FwdIATTotal', 'FwdIATMean', 'FwdIATStd', 'FwdIATMax',\n","       'FwdIATMin', 'BwdIATTotal', 'BwdIATMean', 'BwdIATStd', 'BwdIATMax',\n","       'BwdIATMin', 'FwdPSHFlags', 'FwdHeaderLength', 'BwdHeaderLength',\n","       'FwdPackets/s', 'BwdPackets/s', 'MinPacketLength', 'MaxPacketLength',\n","       'PacketLengthMean', 'PacketLengthStd', 'PacketLengthVariance',\n","       'FINFlagCount', 'SYNFlagCount', 'RSTFlagCount', 'PSHFlagCount',\n","       'ACKFlagCount', 'URGFlagCount', 'ECEFlagCount', 'Down/UpRatio',\n","       'AveragePacketSize', 'AvgFwdSegmentSize', 'AvgBwdSegmentSize',\n","       'FwdHeaderLength.1', 'SubflowFwdPackets', 'SubflowFwdBytes',\n","       'SubflowBwdPackets', 'SubflowBwdBytes', 'Init_Win_bytes_forward',\n","       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n","       'ActiveMean', 'ActiveStd', 'ActiveMax', 'ActiveMin', 'IdleMean',\n","       'IdleStd', 'IdleMax', 'IdleMin', 'Label'],\n","      dtype='object')\n","Data Shape before droping NULL and INF values: \n","(190911, 68)\n","Data Shape before droping NULL and INF values: \n","(72330, 68)\n","After Preprocesing: Total: (72330, 68)\n","After Preprocesing: Normal: (70374, 68)\n","After Preprocesing: Bots: (1956, 68)\n","File: CIC_Friday_bot.csv_(Preprocessed).csv Saving ...\n","File: CIC_Friday_bot.csv_(Preprocessed).csv saved to directory\n","Dataset preprocessed: CIC-2017\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4z4DSSZUrmEt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465248263,"user_tz":-300,"elapsed":53,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"5e44cfff-1e63-478c-ec6c-1a5ed5167a0f"},"source":["training_data = training_data.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\").reset_index(drop=True)\n","print(training_data.describe())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       FlowDuration  TotalFwdPackets  ...       IdleMin         Label\n","count  72330.000000     72330.000000  ...  72330.000000  72330.000000\n","mean       0.214622         0.000057  ...      0.048643      0.972957\n","std        0.353401         0.000263  ...      0.116318      0.162209\n","min        0.000000         0.000000  ...      0.000000      0.000000\n","25%        0.000002         0.000000  ...      0.000000      1.000000\n","50%        0.009819         0.000024  ...      0.000000      1.000000\n","75%        0.291335         0.000063  ...      0.066270      1.000000\n","max        1.000000         0.028342  ...      1.000000      1.000000\n","\n","[8 rows x 68 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xRi-ce1ArmEt"},"source":["<a id=\"GPU Settings\"><h2>Display Features</h2></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"baJvBLfermEu"},"source":["if DISPLAY_FEATURES: \n","    unified_df = training_data.copy()\n","    X_cols = unified_df.columns[:-1]\n","    y_cols = unified_df.columns[-1]\n","\n","\n","\n","    axarr = [[]]*len(X_cols)\n","    columns = 4\n","    rows = int( np.ceil( len(X_cols) / columns ) )\n","    f, fig = plt.subplots( figsize=(columns*2.5, rows*2) )\n","\n","    f.suptitle('Data Distributions by Feature and Label', size=16)\n","\n","    for i, col in enumerate(X_cols[:]):\n","        axarr[i] = plt.subplot2grid( (int(rows), int(columns)), (int(i//columns), int(i%columns)) )\n","\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 0, col ] , label=['Normal'], color=('#009933'), alpha=0.5,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 1, col ] , label=['Real Bot'], color=['#FF0000'], alpha=0.5,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","        axarr[i].set_xlabel(col, size=12)\n","    #     axarr[i].set_ylim([0,1])\n","        axarr[i].tick_params(axis='both', labelsize=10)\n","        if i == 0: \n","            legend = axarr[i].legend()\n","            legend.get_frame().set_facecolor('white')\n","        if i%4 != 0 : \n","            axarr[i].tick_params(axis='y', left=True, labelleft=True)\n","        else:\n","            axarr[i].set_ylabel('Fraction',size=12)\n","\n","    plt.tight_layout(rect=[0,0,1,0.95]) # xmin, ymin, xmax, ymax\n","    # plt.savefig('plots/Engineered_Data_Distributions.png')\n","\n","    plt.show()\n","    \n","# else: \n","#     print('Pair Plotting..')\n","# #     sns.pairplot(training_data, hue=\"Label\")\n","    \n","#     sns.pairplot(training_data, vars=['Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n","#        'Total Length of Fwd Packet', 'Total Length of Bwd Packet'], hue=\"Label\")\n","    \n","#     sns.pairplot(penguins, hue=\"species\", markers=[\"o\", \"s\", \"D\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A2pP9BTTrmEu"},"source":["<a id=\"GPU Settings\"><h2>Select Botnet</h2></a>"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"N-R9pY5ZrmEv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465248271,"user_tz":-300,"elapsed":46,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"e676c15c-c53d-4cf0-e867-a25b18d48aec"},"source":["bots = training_data.loc[ training_data['Label']==0 ].copy()\n","normal = training_data.loc[ training_data['Label']==1 ].copy()\n","\n","print('Normal before chunk: ' + str(normal.shape))    \n","print('Real Bots before chunk: ' + str(bots.shape)) \n","\n","if take_chunk:\n","    bots = bots[0:512]\n","    \n","print('Normal: ' + str(normal.shape))    \n","print('Real Bots: ' + str(bots.shape)) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Normal before chunk: (70374, 68)\n","Real Bots before chunk: (1956, 68)\n","Normal: (70374, 68)\n","Real Bots: (1956, 68)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4xvFewwSrmEv"},"source":["Train = training_data.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"uheTkJQQrmEw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465248275,"user_tz":-300,"elapsed":41,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"501e5b28-48a2-415a-8218-321daa2d35e5"},"source":["bots_count =  pd.DataFrame( [ [np.sum(bots['Label']==i)] for i in np.unique(bots['Label']) ], columns=['count'], index=np.unique(bots['Label']) )\n","\n","label_cols = [ i for i in bots.columns if 'Label' in i ]\n","data_cols = [ i for i in bots.columns if i not in label_cols ]\n","\n","train_no_label = bots[ data_cols ].reset_index(drop=True)\n","\n","print(bots_count['count'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0    1956\n","Name: count, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4RX5ZdlKrmEw"},"source":["train_data = bots"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rn24nPf7rmEx"},"source":["<a id=\"Classification\"><h1>Classification</h1></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"i-9DOIHormEx","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1627465249807,"user_tz":-300,"elapsed":1566,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"2af901f3-6ad3-4eae-ff57-53437df36999"},"source":["%%time \n","# if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","if USE_KMEANS_FOR_CLASSIFICATION:\n","    algorithms = [ \n","    #     [ 'KMeans', cluster.KMeans, (), {'random_state':0} ],\n","        [ 'KMeans', cluster.KMeans, (), {'n_clusters':1, 'random_state':0} ],\n","    #     [ 'KMeans 3', cluster.KMeans, (), {'n_clusters':3, 'random_state':0} ],\n","    #     [ 'Agglomerative', cluster.AgglomerativeClustering, (), {} ],\n","    #     [ 'Agglomerative', cluster.AgglomerativeClustering, (), {'linkage': 'ward', 'n_clusters': 3} ],\n","    #     [ 'Agg. Ave 3', cluster.AgglomerativeClustering, (), {'linkage': 'average', 'n_clusters': 3} ],\n","    #     [ 'Agg. Complete 3', cluster.AgglomerativeClustering, (), {'linkage': 'complete', 'n_clusters': 3} ],\n","    #     [ 'DBSCAN', cluster.DBSCAN, (), {'eps':0.025} ],\n","    #     [ 'HDBSCAN', hdbscan.HDBSCAN, (), {} ],\n","    #     [ 'HDBSCAN', hdbscan.HDBSCAN, (), {'min_cluster_size':10, 'min_samples':1, } ],\n","    #     [ 'HDBSCAN 2 10', hdbscan.HDBSCAN, (), {'min_cluster_size':2, 'min_samples':10, } ],\n","    #     [ 'HDBSCAN 10 10 ', hdbscan.HDBSCAN, (), {'min_cluster_size':10, 'min_samples':10, } ],\n","    ]\n","\n","    rows = len(algorithms)\n","    columns = 1\n","    fig, ax = plt.subplots(3, 2, figsize=(3, 2),\n","                            constrained_layout=True)\n","\n","    for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","        labels = algorithm(*args, **kwds).fit_predict(train_no_label)\n","        print(len(labels))\n","        colors = np.clip(labels,-1,9)\n","        colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","        plt.subplot(rows,columns,i*columns+1)\n","        plt.scatter(train_no_label[data_cols[0]], train_no_label[data_cols[1]], c=colors)\n","        plt.xlabel(data_cols[0]), plt.ylabel(data_cols[1])\n","        plt.title(name)\n","            \n","\n","#     else:\n","#         labels = train_bots_only['Label'].values.tolist() \n","#         sns.set(style=\"ticks\", color_codes=True) # Remove background and grid\n","\n","#     #     g = sns.scatterplot(data_cols[0],data_cols[1], data=train, hue=labels)\n","\n","#     #     plt.show() \n","\n","\n","#         plt.figure()\n","#         ax = sns.countplot(y=\"Label\", data=train_bots_only) # for Seaborn version 0.7 and more\n","#         for p in ax.patches:\n","#             ax.text(p.get_y() + p.get_width() + 2700 , p.get_y()+p.get_height()-0.1, p.get_width(), ha=\"center\") \n","\n","#         ax.set_ylabel('Botnets')\n","\n","#         plt.savefig('Botnet-Trainset.pdf', dpi=600)\n","#         plt.show()\n","\n","\n","\n","\n","#         plt.figure(figsize=(6, 6))\n","#         ax = sns.countplot(y=\"Label\", data=test_bots_only) # for Seaborn version 0.7 and more\n","#         for p in ax.patches:\n","#             ax.text(p.get_y() + p.get_width() + 6000 , p.get_y()+p.get_height()-0.1, p.get_width(), ha=\"center\") \n","\n","#         ax.set_ylabel('Botnets')\n","\n","#         plt.savefig('Botnet-Testset.pdf', dpi=600)\n","#         plt.show()\n","\n","#     #     g = sns.catplot(x=\"class\", hue=\"who\", col=\"survived\", data=titanic, kind=\"count\", height=4, aspect=.7);\n","\n","\n","#     #     sns.pairplot(data=train, vars=[data_cols[0], data_cols[1]], hue='Label')\n","\n","\n","#     # plt.grid(False)\n","#     # plt.show()\n","#     print(train_no_label.describe())\n","    \n","    botnet_w_classes = train_no_label.copy()\n","    botnet_w_classes['Label'] = labels\n","\n","#     print(botnet_w_classes.describe())\n","    train_data = botnet_w_classes\n","    \n","# else:\n","#     train_data = train_no_label\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1956\n","CPU times: user 189 ms, sys: 86.1 ms, total: 275 ms\n","Wall time: 177 ms\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 216x144 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"3hB4cYD2rmEy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465249810,"user_tz":-300,"elapsed":22,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"a9c6fe40-7678-47c7-c68b-6baddb5b8501"},"source":["train_data['Label']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       0\n","1       0\n","2       0\n","3       0\n","4       0\n","       ..\n","1951    0\n","1952    0\n","1953    0\n","1954    0\n","1955    0\n","Name: Label, Length: 1956, dtype: int32"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"O7x626jxrmEz"},"source":["<a id=\"GPU Settings\"><h2>GAN Training</h2></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"tags":[],"id":"PtEhJjhArmEz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465833072,"user_tz":-300,"elapsed":583277,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"399a76aa-47c5-467c-c508-d64a1c5c3e0d"},"source":["# import header\n","# import importlib\n","# importlib.reload(header) # For reloading after making changes\n","# from header import *\n","\n","\n","gpu_device = '/device:GPU:2'\n","physical_devices = tf.config.list_physical_devices('GPU') \n","for gpu_instance in physical_devices: \n","    tf.config.experimental.set_memory_growth(gpu_instance, True)\n","\n","#----------------------------------\n","# Set neurons and batch size\n","#----------------------------------\n","if GAN_type == 'GAN':\n","    base_n_count = 256\n","    batch_size =  128\n","elif GAN_type == 'CGAN':\n","    base_n_count = 256\n","    batch_size =  128\n","elif GAN_type == 'WGAN':\n","    base_n_count = 128\n","    batch_size =  256\n","elif GAN_type == 'WCGAN':\n","    base_n_count = 128\n","    batch_size =  128\n","    \n","elif GAN_type == 'EVAGAN_CC':\n","    base_n_count = 256\n","    batch_size =  256\n","    \n","elif GAN_type == 'ACGAN_CC':\n","    base_n_count = 256\n","    batch_size =  256\n","    \n","elif GAN_type == 'ACGAN_CV':\n","    base_n_count = 32\n","    batch_size =  32\n","    \n","elif GAN_type == 'EVAGAN_CV':\n","    base_n_count = 256\n","    batch_size =  256\n","#----------------------------------\n","\n","\n","result = train_data\n","\n","remaining = train_data.shape[0] % batch_size\n","\n","if remaining > 0:\n","    if remaining < train_data.shape[0]:\n","        additional = batch_size - remaining\n","        _additional = train_data.loc[train_data.shape[0]-additional:train_data.shape[0],: ]  \n","        \n","        frames = [train_data, _additional]\n","        result = pd.concat(frames).reset_index(drop=True)\n","\n","print('Result: ' + str(result.shape))\n","# ---------------------------------\n","nb_steps = required_epochs * result.shape[0] // batch_size\n","\n","log_interval = result.shape[0] // batch_size # We are setting this as an epoch. This depends on data size.\n","\n","print(\"log_interval : \" + str(log_interval))\n","\n","# nb_steps = TRAINING_ITERATIONS  # 50000 # Add one for logging of the last interval\n","print(\"Total Batch Iterations: \" + str(nb_steps))\n","rand_noise_dim = 100 \n","\n","\n","k_d = 1  # number of critic network updates per adversarial training step\n","k_g = 1  # number of generator network updates per adversarial training step\n","\n","critic_pre_train_steps = 100# 100  # number of steps to pre-train the critic before starting adversarial training\n","\n","generator_model_path, discriminator_model_path, loss_pickle_path = None, None, None\n","\n","show = True \n","train = result#.copy().reset_index(drop=True) # botnet only with labels from classification\n","\n","\n","\n","label_cols = [ i for i in train.columns if 'Label' in i ]\n","\n","data_cols = [ i for i in train.columns if i not in label_cols ]\n","\n","print(data_cols)\n","\n","train_no_label = train[ data_cols ]\n","\n","train_no_label = round(train_no_label, 4)\n","\n","# if SAVE_ONLY_BOT_DATA:\n","#     train_no_label.to_csv(str(DATA_SET_PATH) + 'ONLY_BOTNET_DATA_(Preprocessed).csv')\n","#     print('File: ' + 'ONLY_BOTNET_DATA_(Preprocessed).csv saved to directory')   \n","\n","\n","\n","test_size = train.shape[0] \n","learning_rate = 5e-4\n","\n","for X in range(1):\n","\n","    TODAY = DATA_SET + '_' + str(datetime.datetime.now()) \n","\n","    print(TODAY)\n","\n","    Test = testing_data.copy()\n","\n","    arguments = [rand_noise_dim, nb_steps, batch_size, \n","                k_d, k_g, critic_pre_train_steps, log_interval, learning_rate, base_n_count,\n","                CACHE_PATH, FIGS_PATH, show, test_size, gpu_device, EVALUATION_PARAMETER, TODAY ]\n","\n","    if GAN_type == 'GAN':\n","        best_losses = adversarial_training_GAN(arguments, train_no_label, data_cols) # GAN    \n","    elif GAN_type == 'CGAN':    \n","        best_losses = adversarial_training_CGAN(arguments, train, data_cols=data_cols, label_cols=label_cols ) # CGAN      \n","    elif GAN_type == 'WGAN':\n","        best_losses = adversarial_training_WGAN(arguments, train_no_label, data_cols) # WGAN    \n","    elif GAN_type == 'WCGAN':    \n","        best_losses = adversarial_training_WCGAN(arguments, train, data_cols=data_cols, label_cols=label_cols ) # WCGAN      \n","\n","\n","    # if GAN_type == 'WGAN':\n","    #     best_losses = train_WGAN(arguments, train_no_label, data_cols)\n","\n","    # elif GAN_type == 'GAN':\n","    #     best_losses = train_GAN(arguments, train_no_label, data_cols)\n","\n","\n","    elif GAN_type == 'EVAGAN_CC':   \n","\n","        best_losses = train_EVAGAN_CC(arguments, train, Train, Test, data_cols)\n","\n","    elif GAN_type == 'EVAGAN_CV':   \n","\n","        best_losses = train_EVAGAN_CV(arguments, train, Train, Test, data_cols)\n","\n","\n","\n","    elif GAN_type == 'ACGAN_CC':   \n","\n","        best_losses = train_ACGAN_CC(arguments, train, Train, Test, data_cols)\n","\n","    elif GAN_type == 'ACGAN_CV':   \n","\n","        best_losses = train_ACGAN_CV(arguments, train, Train, Test, data_cols)\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Result: (2048, 68)\n","log_interval : 8\n","Total Batch Iterations: 1200\n","['FlowDuration', 'TotalFwdPackets', 'TotalBackwardPackets', 'TotalLengthofFwdPackets', 'TotalLengthofBwdPackets', 'FwdPacketLengthMax', 'FwdPacketLengthMin', 'FwdPacketLengthMean', 'FwdPacketLengthStd', 'BwdPacketLengthMax', 'BwdPacketLengthMin', 'BwdPacketLengthMean', 'BwdPacketLengthStd', 'FlowBytes/s', 'FlowPackets/s', 'FlowIATMean', 'FlowIATStd', 'FlowIATMax', 'FlowIATMin', 'FwdIATTotal', 'FwdIATMean', 'FwdIATStd', 'FwdIATMax', 'FwdIATMin', 'BwdIATTotal', 'BwdIATMean', 'BwdIATStd', 'BwdIATMax', 'BwdIATMin', 'FwdPSHFlags', 'FwdHeaderLength', 'BwdHeaderLength', 'FwdPackets/s', 'BwdPackets/s', 'MinPacketLength', 'MaxPacketLength', 'PacketLengthMean', 'PacketLengthStd', 'PacketLengthVariance', 'FINFlagCount', 'SYNFlagCount', 'RSTFlagCount', 'PSHFlagCount', 'ACKFlagCount', 'URGFlagCount', 'ECEFlagCount', 'Down/UpRatio', 'AveragePacketSize', 'AvgFwdSegmentSize', 'AvgBwdSegmentSize', 'FwdHeaderLength.1', 'SubflowFwdPackets', 'SubflowFwdBytes', 'SubflowBwdPackets', 'SubflowBwdBytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward', 'ActiveMean', 'ActiveStd', 'ActiveMax', 'ActiveMin', 'IdleMean', 'IdleStd', 'IdleMax', 'IdleMin']\n","CIC-2017_2021-07-28 09:40:48.269885\n","[]\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 32)                3232      \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 32)                128       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","activation (Activation)      (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 64)                256       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               8320      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 128)               0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 128)               512       \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 67)                8643      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 67)                0         \n","=================================================================\n","Total params: 23,203\n","Trainable params: 22,755\n","Non-trainable params: 448\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_4 (Dense)              (None, 128)               8704      \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 128)               0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 128)               512       \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 64)                256       \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 32)                2080      \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 32)                128       \n","=================================================================\n","Total params: 19,936\n","Trainable params: 19,488\n","Non-trainable params: 448\n","_________________________________________________________________\n","Directory 'CIC-2017_2021-07-28 09:40:48.269885' created\n","Directory 'CIC-2017_2021-07-28 09:40:48.269885' created\n","ACGAN_CC 256 256\n","======================================================\n","Batch Size Selected -------->>>>>>> 256\n","======================================================\n","(70374, 68)\n","(1956, 68)\n","T_n: (49261, 68)\n","(1369, 68) (49261, 68)\n","Starting GAN Training..\n","G_Z.shape: (587, 67)\n","log_iteration: 1/150\n","Average time per log_iteration: 22.88878297805786\n","Time left = 57.0 minutes\n","Total Time Taken: 0.4 minutes\n","Epoch#: 0 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 2/150\n","Average time per log_iteration: 13.252429962158203\n","Time left = 32.4 minutes\n","Total Time Taken: 0.4 minutes\n","Epoch#: 1 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 3/150\n","Average time per log_iteration: 10.165207703908285\n","Time left = 24.6 minutes\n","Total Time Taken: 0.5 minutes\n","Epoch#: 2 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 4/150\n","Average time per log_iteration: 8.608215868473053\n","Time left = 21.0 minutes\n","Total Time Taken: 0.6 minutes\n","Epoch#: 3 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 5/150\n","Average time per log_iteration: 7.591306591033936\n","Time left = 18.6 minutes\n","Total Time Taken: 0.6 minutes\n","Epoch#: 4 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 6/150\n","Average time per log_iteration: 6.987508058547974\n","Time left = 16.8 minutes\n","Total Time Taken: 0.7 minutes\n","Epoch#: 5 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 7/150\n","Average time per log_iteration: 6.557240894862583\n","Time left = 15.6 minutes\n","Total Time Taken: 0.8 minutes\n","Epoch#: 6 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 8/150\n","Average time per log_iteration: 6.1750927567481995\n","Time left = 14.4 minutes\n","Total Time Taken: 0.8 minutes\n","Epoch#: 7 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 9/150\n","Average time per log_iteration: 5.9262124167548285\n","Time left = 13.8 minutes\n","Total Time Taken: 0.9 minutes\n","Epoch#: 8 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 10/150\n","Average time per log_iteration: 5.67997887134552\n","Time left = 13.2 minutes\n","Total Time Taken: 0.9 minutes\n","Epoch#: 9 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 11/150\n","Average time per log_iteration: 5.475600979544899\n","Time left = 12.6 minutes\n","Total Time Taken: 1.0 minutes\n","Epoch#: 10 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 12/150\n","Average time per log_iteration: 5.349980473518372\n","Time left = 12.0 minutes\n","Total Time Taken: 1.1 minutes\n","Epoch#: 11 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 13/150\n","Average time per log_iteration: 5.194950415537908\n","Time left = 12.0 minutes\n","Total Time Taken: 1.1 minutes\n","Epoch#: 12 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 14/150\n","Average time per log_iteration: 5.097248809678214\n","Time left = 11.4 minutes\n","Total Time Taken: 1.2 minutes\n","Epoch#: 13 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 15/150\n","Average time per log_iteration: 5.014506419499715\n","Time left = 11.4 minutes\n","Total Time Taken: 1.3 minutes\n","Epoch#: 14 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 16/150\n","Average time per log_iteration: 4.9438488483428955\n","Time left = 10.8 minutes\n","Total Time Taken: 1.3 minutes\n","Epoch#: 15 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 17/150\n","Average time per log_iteration: 4.88447185123668\n","Time left = 10.8 minutes\n","Total Time Taken: 1.4 minutes\n","Epoch#: 16 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 18/150\n","Average time per log_iteration: 4.81303264035119\n","Time left = 10.8 minutes\n","Total Time Taken: 1.4 minutes\n","Epoch#: 17 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 19/150\n","Average time per log_iteration: 4.778804201828806\n","Time left = 10.2 minutes\n","Total Time Taken: 1.5 minutes\n","Epoch#: 18 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 20/150\n","Average time per log_iteration: 4.742739713191986\n","Time left = 10.2 minutes\n","Total Time Taken: 1.6 minutes\n","Epoch#: 19 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 21/150\n","Average time per log_iteration: 4.712028707776751\n","Time left = 10.2 minutes\n","Total Time Taken: 1.6 minutes\n","Epoch#: 20 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 22/150\n","Average time per log_iteration: 4.685551448301836\n","Time left = 10.2 minutes\n","Total Time Taken: 1.7 minutes\n","Epoch#: 21 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 23/150\n","Average time per log_iteration: 4.644605304883874\n","Time left = 9.6 minutes\n","Total Time Taken: 1.8 minutes\n","Epoch#: 22 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 24/150\n","Average time per log_iteration: 4.590945015350978\n","Time left = 9.6 minutes\n","Total Time Taken: 1.8 minutes\n","Epoch#: 23 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 25/150\n","Average time per log_iteration: 4.56412220954895\n","Time left = 9.6 minutes\n","Total Time Taken: 1.9 minutes\n","Epoch#: 24 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 26/150\n","Average time per log_iteration: 4.544109885509197\n","Time left = 9.6 minutes\n","Total Time Taken: 2.0 minutes\n","Epoch#: 25 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 27/150\n","Average time per log_iteration: 4.504788469385217\n","Time left = 9.0 minutes\n","Total Time Taken: 2.0 minutes\n","Epoch#: 26 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 28/150\n","Average time per log_iteration: 4.466756369386401\n","Time left = 9.0 minutes\n","Total Time Taken: 2.1 minutes\n","Epoch#: 27 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 29/150\n","Average time per log_iteration: 4.447832987226289\n","Time left = 9.0 minutes\n","Total Time Taken: 2.1 minutes\n","Epoch#: 28 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 30/150\n","Average time per log_iteration: 4.433098928133647\n","Time left = 9.0 minutes\n","Total Time Taken: 2.2 minutes\n","Epoch#: 29 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 31/150\n","Average time per log_iteration: 4.403584157266924\n","Time left = 9.0 minutes\n","Total Time Taken: 2.3 minutes\n","Epoch#: 30 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 32/150\n","Average time per log_iteration: 4.373296961188316\n","Time left = 8.4 minutes\n","Total Time Taken: 2.3 minutes\n","Epoch#: 31 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 33/150\n","Average time per log_iteration: 4.3486035520380195\n","Time left = 8.4 minutes\n","Total Time Taken: 2.4 minutes\n","Epoch#: 32 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 34/150\n","Average time per log_iteration: 4.322886067278245\n","Time left = 8.4 minutes\n","Total Time Taken: 2.4 minutes\n","Epoch#: 33 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 35/150\n","Average time per log_iteration: 4.317643914903913\n","Time left = 8.4 minutes\n","Total Time Taken: 2.5 minutes\n","Epoch#: 34 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 36/150\n","Average time per log_iteration: 4.299749010139042\n","Time left = 8.4 minutes\n","Total Time Taken: 2.6 minutes\n","Epoch#: 35 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 37/150\n","Average time per log_iteration: 4.295712277695939\n","Time left = 7.8 minutes\n","Total Time Taken: 2.6 minutes\n","Epoch#: 36 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 38/150\n","Average time per log_iteration: 4.292199316777681\n","Time left = 7.8 minutes\n","Total Time Taken: 2.7 minutes\n","Epoch#: 37 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 39/150\n","Average time per log_iteration: 4.2883728589767065\n","Time left = 7.8 minutes\n","Total Time Taken: 2.8 minutes\n","Epoch#: 38 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 40/150\n","Average time per log_iteration: 4.283134484291077\n","Time left = 7.8 minutes\n","Total Time Taken: 2.9 minutes\n","Epoch#: 39 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 41/150\n","Average time per log_iteration: 4.264197151835372\n","Time left = 7.8 minutes\n","Total Time Taken: 2.9 minutes\n","Epoch#: 40 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 42/150\n","Average time per log_iteration: 4.2573386714572\n","Time left = 7.8 minutes\n","Total Time Taken: 3.0 minutes\n","Epoch#: 41 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 43/150\n","Average time per log_iteration: 4.249574278676232\n","Time left = 7.8 minutes\n","Total Time Taken: 3.0 minutes\n","Epoch#: 42 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 44/150\n","Average time per log_iteration: 4.233935740861026\n","Time left = 7.2 minutes\n","Total Time Taken: 3.1 minutes\n","Epoch#: 43 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 45/150\n","Average time per log_iteration: 4.22541085879008\n","Time left = 7.2 minutes\n","Total Time Taken: 3.2 minutes\n","Epoch#: 44 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 46/150\n","Average time per log_iteration: 4.2179427717043\n","Time left = 7.2 minutes\n","Total Time Taken: 3.2 minutes\n","Epoch#: 45 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 47/150\n","Average time per log_iteration: 4.200594612892638\n","Time left = 7.2 minutes\n","Total Time Taken: 3.3 minutes\n","Epoch#: 46 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 48/150\n","Average time per log_iteration: 4.184051995476087\n","Time left = 7.2 minutes\n","Total Time Taken: 3.3 minutes\n","Epoch#: 47 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 49/150\n","Average time per log_iteration: 4.167818916087248\n","Time left = 7.2 minutes\n","Total Time Taken: 3.4 minutes\n","Epoch#: 48 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 50/150\n","Average time per log_iteration: 4.159465236663818\n","Time left = 7.2 minutes\n","Total Time Taken: 3.5 minutes\n","Epoch#: 49 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 51/150\n","Average time per log_iteration: 4.144651922525144\n","Time left = 6.6 minutes\n","Total Time Taken: 3.5 minutes\n","Epoch#: 50 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 52/150\n","Average time per log_iteration: 4.142896367953374\n","Time left = 6.6 minutes\n","Total Time Taken: 3.6 minutes\n","Epoch#: 51 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 53/150\n","Average time per log_iteration: 4.141293831591336\n","Time left = 6.6 minutes\n","Total Time Taken: 3.7 minutes\n","Epoch#: 52 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 54/150\n","Average time per log_iteration: 4.139782636253922\n","Time left = 6.6 minutes\n","Total Time Taken: 3.7 minutes\n","Epoch#: 53 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 55/150\n","Average time per log_iteration: 4.137989677082409\n","Time left = 6.6 minutes\n","Total Time Taken: 3.8 minutes\n","Epoch#: 54 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 56/150\n","Average time per log_iteration: 4.135817830051694\n","Time left = 6.6 minutes\n","Total Time Taken: 3.9 minutes\n","Epoch#: 55 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 57/150\n","Average time per log_iteration: 4.1267834629928855\n","Time left = 6.6 minutes\n","Total Time Taken: 3.9 minutes\n","Epoch#: 56 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 58/150\n","Average time per log_iteration: 4.126962924825734\n","Time left = 6.6 minutes\n","Total Time Taken: 4.0 minutes\n","Epoch#: 57 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 59/150\n","Average time per log_iteration: 4.114209825709715\n","Time left = 6.0 minutes\n","Total Time Taken: 4.0 minutes\n","Epoch#: 58 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 60/150\n","Average time per log_iteration: 4.11163436571757\n","Time left = 6.0 minutes\n","Total Time Taken: 4.1 minutes\n","Epoch#: 59 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 61/150\n","Average time per log_iteration: 4.101555914175315\n","Time left = 6.0 minutes\n","Total Time Taken: 4.2 minutes\n","Epoch#: 60 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 62/150\n","Average time per log_iteration: 4.100752453650197\n","Time left = 6.0 minutes\n","Total Time Taken: 4.2 minutes\n","Epoch#: 61 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 63/150\n","Average time per log_iteration: 4.092164660257007\n","Time left = 6.0 minutes\n","Total Time Taken: 4.3 minutes\n","Epoch#: 62 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 64/150\n","Average time per log_iteration: 4.080740496516228\n","Time left = 6.0 minutes\n","Total Time Taken: 4.4 minutes\n","Epoch#: 63 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 65/150\n","Average time per log_iteration: 4.078703803282518\n","Time left = 6.0 minutes\n","Total Time Taken: 4.4 minutes\n","Epoch#: 64 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 66/150\n","Average time per log_iteration: 4.068176721081589\n","Time left = 5.4 minutes\n","Total Time Taken: 4.5 minutes\n","Epoch#: 65 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 67/150\n","Average time per log_iteration: 4.057501828492577\n","Time left = 5.4 minutes\n","Total Time Taken: 4.5 minutes\n","Epoch#: 66 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 68/150\n","Average time per log_iteration: 4.047255831606248\n","Time left = 5.4 minutes\n","Total Time Taken: 4.6 minutes\n","Epoch#: 67 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 69/150\n","Average time per log_iteration: 4.045276151187178\n","Time left = 5.4 minutes\n","Total Time Taken: 4.7 minutes\n","Epoch#: 68 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 70/150\n","Average time per log_iteration: 4.03841735294887\n","Time left = 5.4 minutes\n","Total Time Taken: 4.7 minutes\n","Epoch#: 69 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 71/150\n","Average time per log_iteration: 4.039113461131781\n","Time left = 5.4 minutes\n","Total Time Taken: 4.8 minutes\n","Epoch#: 70 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 72/150\n","Average time per log_iteration: 4.038827025228077\n","Time left = 5.4 minutes\n","Total Time Taken: 4.8 minutes\n","Epoch#: 71 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 73/150\n","Average time per log_iteration: 4.039834202152409\n","Time left = 5.4 minutes\n","Total Time Taken: 4.9 minutes\n","Epoch#: 72 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 74/150\n","Average time per log_iteration: 4.034837642231503\n","Time left = 5.4 minutes\n","Total Time Taken: 5.0 minutes\n","Epoch#: 73 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 75/150\n","Average time per log_iteration: 4.034942264556885\n","Time left = 4.8 minutes\n","Total Time Taken: 5.0 minutes\n","Epoch#: 74 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 76/150\n","Average time per log_iteration: 4.034140229225159\n","Time left = 4.8 minutes\n","Total Time Taken: 5.1 minutes\n","Epoch#: 75 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 77/150\n","Average time per log_iteration: 4.025174404119516\n","Time left = 4.8 minutes\n","Total Time Taken: 5.2 minutes\n","Epoch#: 76 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 78/150\n","Average time per log_iteration: 4.017011456000499\n","Time left = 4.8 minutes\n","Total Time Taken: 5.2 minutes\n","Epoch#: 77 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 79/150\n","Average time per log_iteration: 4.00902668735649\n","Time left = 4.8 minutes\n","Total Time Taken: 5.3 minutes\n","Epoch#: 78 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 80/150\n","Average time per log_iteration: 4.000873556733131\n","Time left = 4.8 minutes\n","Total Time Taken: 5.3 minutes\n","Epoch#: 79 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 81/150\n","Average time per log_iteration: 3.9998596538732083\n","Time left = 4.8 minutes\n","Total Time Taken: 5.4 minutes\n","Epoch#: 80 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 82/150\n","Average time per log_iteration: 3.993918546816198\n","Time left = 4.8 minutes\n","Total Time Taken: 5.5 minutes\n","Epoch#: 81 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 83/150\n","Average time per log_iteration: 3.9924794105162102\n","Time left = 4.2 minutes\n","Total Time Taken: 5.5 minutes\n","Epoch#: 82 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 84/150\n","Average time per log_iteration: 3.9863232232275463\n","Time left = 4.2 minutes\n","Total Time Taken: 5.6 minutes\n","Epoch#: 83 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 85/150\n","Average time per log_iteration: 3.9807298968820013\n","Time left = 4.2 minutes\n","Total Time Taken: 5.6 minutes\n","Epoch#: 84 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 86/150\n","Average time per log_iteration: 3.97543427833291\n","Time left = 4.2 minutes\n","Total Time Taken: 5.7 minutes\n","Epoch#: 85 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 87/150\n","Average time per log_iteration: 3.9698303266503343\n","Time left = 4.2 minutes\n","Total Time Taken: 5.8 minutes\n","Epoch#: 86 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 88/150\n","Average time per log_iteration: 3.9703868627548218\n","Time left = 4.2 minutes\n","Total Time Taken: 5.8 minutes\n","Epoch#: 87 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 89/150\n","Average time per log_iteration: 3.967062382215864\n","Time left = 4.2 minutes\n","Total Time Taken: 5.9 minutes\n","Epoch#: 88 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 90/150\n","Average time per log_iteration: 3.9681823703977797\n","Time left = 4.2 minutes\n","Total Time Taken: 6.0 minutes\n","Epoch#: 89 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 91/150\n","Average time per log_iteration: 3.968931664477338\n","Time left = 3.6 minutes\n","Total Time Taken: 6.0 minutes\n","Epoch#: 90 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 92/150\n","Average time per log_iteration: 3.9645924956902214\n","Time left = 3.6 minutes\n","Total Time Taken: 6.1 minutes\n","Epoch#: 91 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 93/150\n","Average time per log_iteration: 3.961490397812218\n","Time left = 3.6 minutes\n","Total Time Taken: 6.1 minutes\n","Epoch#: 92 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 94/150\n","Average time per log_iteration: 3.961782526462636\n","Time left = 3.6 minutes\n","Total Time Taken: 6.2 minutes\n","Epoch#: 93 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 95/150\n","Average time per log_iteration: 3.955938811051218\n","Time left = 3.6 minutes\n","Total Time Taken: 6.3 minutes\n","Epoch#: 94 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 96/150\n","Average time per log_iteration: 3.952316833039125\n","Time left = 3.6 minutes\n","Total Time Taken: 6.3 minutes\n","Epoch#: 95 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 97/150\n","Average time per log_iteration: 3.949034292673327\n","Time left = 3.6 minutes\n","Total Time Taken: 6.4 minutes\n","Epoch#: 96 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 98/150\n","Average time per log_iteration: 3.945290112981991\n","Time left = 3.6 minutes\n","Total Time Taken: 6.4 minutes\n","Epoch#: 97 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 99/150\n","Average time per log_iteration: 3.945843785700172\n","Time left = 3.6 minutes\n","Total Time Taken: 6.5 minutes\n","Epoch#: 98 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 100/150\n","Average time per log_iteration: 3.943108849525452\n","Time left = 3.0 minutes\n","Total Time Taken: 6.6 minutes\n","Epoch#: 99 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 101/150\n","Average time per log_iteration: 3.943874491323339\n","Time left = 3.0 minutes\n","Total Time Taken: 6.6 minutes\n","Epoch#: 100 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 102/150\n","Average time per log_iteration: 3.940536938461603\n","Time left = 3.0 minutes\n","Total Time Taken: 6.7 minutes\n","Epoch#: 101 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 103/150\n","Average time per log_iteration: 3.936177978237856\n","Time left = 3.0 minutes\n","Total Time Taken: 6.8 minutes\n","Epoch#: 102 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 104/150\n","Average time per log_iteration: 3.932123152109293\n","Time left = 3.0 minutes\n","Total Time Taken: 6.8 minutes\n","Epoch#: 103 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 105/150\n","Average time per log_iteration: 3.9278536478678387\n","Time left = 3.0 minutes\n","Total Time Taken: 6.9 minutes\n","Epoch#: 104 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 106/150\n","Average time per log_iteration: 3.9224009221454836\n","Time left = 3.0 minutes\n","Total Time Taken: 6.9 minutes\n","Epoch#: 105 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 107/150\n","Average time per log_iteration: 3.9220507991648166\n","Time left = 3.0 minutes\n","Total Time Taken: 7.0 minutes\n","Epoch#: 106 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 108/150\n","Average time per log_iteration: 3.918208795565146\n","Time left = 3.0 minutes\n","Total Time Taken: 7.1 minutes\n","Epoch#: 107 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 109/150\n","Average time per log_iteration: 3.9137076981570744\n","Time left = 2.4 minutes\n","Total Time Taken: 7.1 minutes\n","Epoch#: 108 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 110/150\n","Average time per log_iteration: 3.9136779460040008\n","Time left = 2.4 minutes\n","Total Time Taken: 7.2 minutes\n","Epoch#: 109 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 111/150\n","Average time per log_iteration: 3.9096246302664817\n","Time left = 2.4 minutes\n","Total Time Taken: 7.2 minutes\n","Epoch#: 110 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 112/150\n","Average time per log_iteration: 3.9049061983823776\n","Time left = 2.4 minutes\n","Total Time Taken: 7.3 minutes\n","Epoch#: 111 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 113/150\n","Average time per log_iteration: 3.900323521774427\n","Time left = 2.4 minutes\n","Total Time Taken: 7.3 minutes\n","Epoch#: 112 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 114/150\n","Average time per log_iteration: 3.9007617172441984\n","Time left = 2.4 minutes\n","Total Time Taken: 7.4 minutes\n","Epoch#: 113 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 115/150\n","Average time per log_iteration: 3.898249677989794\n","Time left = 2.4 minutes\n","Total Time Taken: 7.5 minutes\n","Epoch#: 114 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 116/150\n","Average time per log_iteration: 3.9002378582954407\n","Time left = 2.4 minutes\n","Total Time Taken: 7.5 minutes\n","Epoch#: 115 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 117/150\n","Average time per log_iteration: 3.90189647470784\n","Time left = 2.4 minutes\n","Total Time Taken: 7.6 minutes\n","Epoch#: 116 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 118/150\n","Average time per log_iteration: 3.9051429942502813\n","Time left = 1.8 minutes\n","Total Time Taken: 7.7 minutes\n","Epoch#: 117 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 119/150\n","Average time per log_iteration: 3.9055308874915626\n","Time left = 1.8 minutes\n","Total Time Taken: 7.7 minutes\n","Epoch#: 118 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 120/150\n","Average time per log_iteration: 3.9069749613602958\n","Time left = 1.8 minutes\n","Total Time Taken: 7.8 minutes\n","Epoch#: 119 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 121/150\n","Average time per log_iteration: 3.9068281749063285\n","Time left = 1.8 minutes\n","Total Time Taken: 7.9 minutes\n","Epoch#: 120 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 122/150\n","Average time per log_iteration: 3.9023223157788887\n","Time left = 1.8 minutes\n","Total Time Taken: 7.9 minutes\n","Epoch#: 121 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 123/150\n","Average time per log_iteration: 3.8984769960729087\n","Time left = 1.8 minutes\n","Total Time Taken: 8.0 minutes\n","Epoch#: 122 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 124/150\n","Average time per log_iteration: 3.898497135408463\n","Time left = 1.8 minutes\n","Total Time Taken: 8.1 minutes\n","Epoch#: 123 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 125/150\n","Average time per log_iteration: 3.899145944595337\n","Time left = 1.8 minutes\n","Total Time Taken: 8.1 minutes\n","Epoch#: 124 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 126/150\n","Average time per log_iteration: 3.898493596485683\n","Time left = 1.8 minutes\n","Total Time Taken: 8.2 minutes\n","Epoch#: 125 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 127/150\n","Average time per log_iteration: 3.894163890147772\n","Time left = 1.2 minutes\n","Total Time Taken: 8.2 minutes\n","Epoch#: 126 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 128/150\n","Average time per log_iteration: 3.893434077501297\n","Time left = 1.2 minutes\n","Total Time Taken: 8.3 minutes\n","Epoch#: 127 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 129/150\n","Average time per log_iteration: 3.892637990241827\n","Time left = 1.2 minutes\n","Total Time Taken: 8.4 minutes\n","Epoch#: 128 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 130/150\n","Average time per log_iteration: 3.888426426740793\n","Time left = 1.2 minutes\n","Total Time Taken: 8.4 minutes\n","Epoch#: 129 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 131/150\n","Average time per log_iteration: 3.8885417439555394\n","Time left = 1.2 minutes\n","Total Time Taken: 8.5 minutes\n","Epoch#: 130 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 132/150\n","Average time per log_iteration: 3.885998547077179\n","Time left = 1.2 minutes\n","Total Time Taken: 8.5 minutes\n","Epoch#: 131 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 133/150\n","Average time per log_iteration: 3.88378483908517\n","Time left = 1.2 minutes\n","Total Time Taken: 8.6 minutes\n","Epoch#: 132 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 134/150\n","Average time per log_iteration: 3.8850196938016524\n","Time left = 1.2 minutes\n","Total Time Taken: 8.7 minutes\n","Epoch#: 133 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 135/150\n","Average time per log_iteration: 3.8831243850566723\n","Time left = 1.2 minutes\n","Total Time Taken: 8.7 minutes\n","Epoch#: 134 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 136/150\n","Average time per log_iteration: 3.881612479686737\n","Time left = 1.2 minutes\n","Total Time Taken: 8.8 minutes\n","Epoch#: 135 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 137/150\n","Average time per log_iteration: 3.8798936509738002\n","Time left = 0.6 minutes\n","Total Time Taken: 8.9 minutes\n","Epoch#: 136 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 138/150\n","Average time per log_iteration: 3.8807309935058374\n","Time left = 0.6 minutes\n","Total Time Taken: 8.9 minutes\n","Epoch#: 137 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 139/150\n","Average time per log_iteration: 3.8803854863420666\n","Time left = 0.6 minutes\n","Total Time Taken: 9.0 minutes\n","Epoch#: 138 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 140/150\n","Average time per log_iteration: 3.880264050619943\n","Time left = 0.6 minutes\n","Total Time Taken: 9.1 minutes\n","Epoch#: 139 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 141/150\n","Average time per log_iteration: 3.8804124872735204\n","Time left = 0.6 minutes\n","Total Time Taken: 9.1 minutes\n","Epoch#: 140 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 142/150\n","Average time per log_iteration: 3.8768524183353907\n","Time left = 0.6 minutes\n","Total Time Taken: 9.2 minutes\n","Epoch#: 141 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 143/150\n","Average time per log_iteration: 3.874033944590108\n","Time left = 0.6 minutes\n","Total Time Taken: 9.2 minutes\n","Epoch#: 142 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 144/150\n","Average time per log_iteration: 3.8742759426434836\n","Time left = 0.6 minutes\n","Total Time Taken: 9.3 minutes\n","Epoch#: 143 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 145/150\n","Average time per log_iteration: 3.8742036013767636\n","Time left = 0.6 minutes\n","Total Time Taken: 9.4 minutes\n","Epoch#: 144 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 146/150\n","Average time per log_iteration: 3.8741441769142675\n","Time left = 0.0 minutes\n","Total Time Taken: 9.4 minutes\n","Epoch#: 145 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 147/150\n","Average time per log_iteration: 3.874368194009171\n","Time left = 0.0 minutes\n","Total Time Taken: 9.5 minutes\n","Epoch#: 146 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 148/150\n","Average time per log_iteration: 3.8742005728386544\n","Time left = 0.0 minutes\n","Total Time Taken: 9.6 minutes\n","Epoch#: 147 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 149/150\n","Average time per log_iteration: 3.8715598583221436\n","Time left = 0.0 minutes\n","Total Time Taken: 9.6 minutes\n","Epoch#: 148 completed\n","G_Z.shape: (587, 67)\n","log_iteration: 150/150\n","Average time per log_iteration: 3.8728562116622927\n","Time left = -0.0 minutes\n","Total Time Taken: 9.7 minutes\n","Epoch#: 149 completed\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"as18KSGJy3fR"},"source":["# New section"]},{"cell_type":"code","metadata":{"id":"ISb3Z3GhrmE1"},"source":["# %cd '/home/riz/Insync/rhr407@gmail.com/Google_Drive/PhD/Development/code/Current/Paper_2(v7)/figs/full/GAN/'\n","# !ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZYR3V2JrmE1"},"source":["<a id=\"Columns\"><h1>Columns</h1></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"sLmCv-xMrmE1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465833083,"user_tz":-300,"elapsed":57,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"8f1626d5-b16a-4806-d611-c7ac171bdef3"},"source":["X_cols = training_data.columns[:-1]\n","y_cols = training_data.columns[-1]\n","\n","print('X_cols: ' + str(X_cols))\n","print('y_cols: ' + str(y_cols))\n","\n","X = training_data[X_cols].values\n","Y = training_data['Label'].values\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_cols: Index(['FlowDuration', 'TotalFwdPackets', 'TotalBackwardPackets',\n","       'TotalLengthofFwdPackets', 'TotalLengthofBwdPackets',\n","       'FwdPacketLengthMax', 'FwdPacketLengthMin', 'FwdPacketLengthMean',\n","       'FwdPacketLengthStd', 'BwdPacketLengthMax', 'BwdPacketLengthMin',\n","       'BwdPacketLengthMean', 'BwdPacketLengthStd', 'FlowBytes/s',\n","       'FlowPackets/s', 'FlowIATMean', 'FlowIATStd', 'FlowIATMax',\n","       'FlowIATMin', 'FwdIATTotal', 'FwdIATMean', 'FwdIATStd', 'FwdIATMax',\n","       'FwdIATMin', 'BwdIATTotal', 'BwdIATMean', 'BwdIATStd', 'BwdIATMax',\n","       'BwdIATMin', 'FwdPSHFlags', 'FwdHeaderLength', 'BwdHeaderLength',\n","       'FwdPackets/s', 'BwdPackets/s', 'MinPacketLength', 'MaxPacketLength',\n","       'PacketLengthMean', 'PacketLengthStd', 'PacketLengthVariance',\n","       'FINFlagCount', 'SYNFlagCount', 'RSTFlagCount', 'PSHFlagCount',\n","       'ACKFlagCount', 'URGFlagCount', 'ECEFlagCount', 'Down/UpRatio',\n","       'AveragePacketSize', 'AvgFwdSegmentSize', 'AvgBwdSegmentSize',\n","       'FwdHeaderLength.1', 'SubflowFwdPackets', 'SubflowFwdBytes',\n","       'SubflowBwdPackets', 'SubflowBwdBytes', 'Init_Win_bytes_forward',\n","       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n","       'ActiveMean', 'ActiveStd', 'ActiveMax', 'ActiveMin', 'IdleMean',\n","       'IdleStd', 'IdleMax', 'IdleMin'],\n","      dtype='object')\n","y_cols: Label\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PEWilKKLrmE3"},"source":["<a id=\"Run all Classifiers\"><h1>Split Datasets for Testing)</h1></a>"]},{"cell_type":"code","metadata":{"id":"jpq1rvhOrmE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465833086,"user_tz":-300,"elapsed":50,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"19740126-c35c-4b01-f68d-39aa131dc687"},"source":["if USE_ONLY_TRAIN_SET:\n","\n","    X = training_data[X_cols].values\n","    Y = training_data['Label'].values\n","\n","    # split data into train and test sets\n","    seed = 1\n","    test_size = 0.3\n","    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=11)\n","\n","    split_70_30 = True\n","\n","    print('Using Train set 70:30 split >>>>>>>')\n","\n","else:\n","\n","    X_train = training_data[X_cols].values\n","    y_train = training_data[y_cols].values\n","\n","    X_test = testing_data[X_cols].values\n","    y_test = testing_data[y_cols].values\n","\n","    print('Using Test Set for testing >>>>>>>') \n","\n","    split_70_30 = False\n","    \n","TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","TRAIN_TRAFFIC['Label'] = y_train\n","\n","BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","print('bot samples: ' + str(BOT_COUNTS))  \n","print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS =================================================================================================\n","REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","# REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]\n","\n","print(REAL_BOTS.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using Train set 70:30 split >>>>>>>\n","bot samples: 49248\n","benign samples: 1383\n","(49248, 68)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GauQ1ON4rmE4"},"source":["<a id=\"Case7: Select Test Set\"><h2>Weights for Testing of each Classifier</h2></a>"]},{"cell_type":"code","metadata":{"id":"Vki0AX3prmE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465833088,"user_tz":-300,"elapsed":45,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"55028368-ab13-45f9-8c26-4ca751a55bfb"},"source":["XGB_ACC_WEIGHT = best_losses[0]\n","XGB_RCL_WEIGHT = best_losses[1]\n","\n","DT_ACC_WEIGHT = best_losses[2]\n","DT_RCL_WEIGHT = best_losses[3]\n","\n","NB_ACC_WEIGHT = best_losses[4]\n","NB_RCL_WEIGHT = best_losses[5]\n","\n","RF_ACC_WEIGHT = best_losses[6]\n","RF_RCL_WEIGHT = best_losses[7]\n","\n","LR_ACC_WEIGHT = best_losses[8]\n","LR_RCL_WEIGHT = best_losses[9]\n","\n","KNN_ACC_WEIGHT = best_losses[10]\n","KNN_RCL_WEIGHT = best_losses[11]\n","\n","print(best_losses) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VFziWvq8rmE5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627465833983,"user_tz":-300,"elapsed":934,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"eed8cf51-6c27-46f5-fadb-0f88c688396d"},"source":["import pandas as pd\n","\n","dict = {'Best_Losses': best_losses}   \n","          \n","df = pd.DataFrame(dict) \n","# saving the dataframe  \n","# =============================================================================================    \n","df.to_csv(str(DATA_SET_PATH) + 'best_losses.csv')\n","print('File: ' + str(DATA_SET_PATH) + 'best_losses.csv saved to directory')  \n","# =============================================================================================    \n","print('Losses file saved')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["File: /content/drive/My Drive/PhD/Development/code/Current/EVAGAN/Dataset/CIC-2017/best_losses.csv saved to directory\n","Losses file saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KvJkzW0VrmE5"},"source":["# if DATA_SET=='ISCX-2014':\n","#     if GAN_type=='GAN':\n","#         best_losses = [92, 15, 0, 99, 44, 44, 51, 107, 116, 116, 51, 51]\n","#     elif GAN_type=='CGAN':\n","#         best_losses = [100, 100, 121, 20, 102, 102, 100, 100,77, 77, 44, 44]\n","        \n","# elif DATA_SET=='CIC-2017':\n","#     if GAN_type=='GAN':\n","#         best_losses = [118, 118, 118, 118, 103, 103, 134, 134, 110, 110, 120, 127]\n","#     elif GAN_type=='CGAN':\n","#         best_losses = [69, 40, 139, 115, 80, 80, 80, 80, 0, 0, 40, 40]\n","\n","# elif DATA_SET=='CIC-2018':\n","#     if GAN_type=='GAN':\n","#         best_losses = [62, 62, 58, 58, 67, 67, 27, 27, 68, 68, 68, 68]\n","#     elif GAN_type=='CGAN':\n","#         best_losses = [114, 138, 93, 93, 0, 0, 14, 14, 121, 121, 121, 121]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZlZ3OXqwrmE6"},"source":["<a id=\"Case7: Select Test Set\"><h1>KDE</h1></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"j08bshJarmE6","colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"status":"error","timestamp":1627465834018,"user_tz":-300,"elapsed":103,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"c7dc1419-8ac6-4ed5-e0dd-8b0dcc131265"},"source":["\n","import header\n","import importlib\n","importlib.reload(header) # For reloading after making changes\n","from header import *\n","\n","real_bots_df = bots[X_cols].copy()\n","real_bots_df['Type'] = 'Real Bots'\n","\n","print(real_bots_df.shape)\n","\n","# fig, ax = plt.subplots(6, 1, figsize=(1, 5), constrained_layout=True)\n","for i in range(0, len(best_losses), 2):\n","    \n","    gan_bots_acc = generate_gan_data(real_bots_df, labels = labels, weight_or_epoch_number = best_losses[i], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","    gan_bots_rcl = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i+1], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","    \n","    print(gan_bots_acc.shape)\n","    print(gan_bots_rcl.shape)\n","\n","#     gan_bots_acc = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","#     gan_bots_rcl = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = 32, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","    \n","    gan_bots_acc['Type'] = 'GAN Bots (C2ST)'\n","    gan_bots_rcl['Type'] = 'GAN Bots (BotShot)'\n","\n","\n","    data_frame = pd.concat([gan_bots_acc, gan_bots_rcl]).reset_index(drop=True).copy()\n","    data_frame_of_bots = pd.concat([real_bots_df, data_frame]).reset_index(drop=True).copy()\n","    \n","    # =============================================================================================    \n","    data_frame_of_bots.to_csv(str(DATA_SET_PATH) + GAN_type + '_data_frame_of_bots_' + str(i) + '.csv')\n","    print('File: ' + str(DATA_SET_PATH) + GAN_type + '_data_frame_of_bots_' + str(i) + '.csv saved to directory')  \n","    # =============================================================================================    \n","\n","    print(gan_bots_acc.shape)\n","    print(gan_bots_rcl.shape)\n","#     fig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\n","\n","\n","#     for j in range(len(data_cols)):\n","#         print(j)\n","#     sns.kdeplot(data = data_frame_of_bots, x = data_cols[44], y = data_cols[45],  bw_adjust=7, fill = False, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","#     sns.displot(data=data_frame_of_bots, x=data_cols[44], kind=\"kde\", hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'], bw_adjust=7)\n","    \n","\n","    fig, ax = pyplot.subplots(figsize=(5, 3.5))\n","\n","#     plt.xlim(-2, 2)\n","#     plt.ylim(-2, 1) \n","\n","    if DATA_SET=='CIC-2017':\n","        X = 'BwdPacketLengthStd'\n","    else:\n","        X = 'Bwd Pkt Len Std'\n","\n","    \n","    for j in range(len(data_cols)):\n","        print(j)\n","        g = sns.kdeplot(data = data_frame_of_bots, x = data_cols[j], bw_adjust=6, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'],  fill=False, common_norm=False, alpha=.6)\n","        plt.xlim(-1, 3)\n","        plt.ylim(-1, 3)\n","        \n","        \n","        plt.show()\n","        plt.close()\n","#     g = sns.kdeplot(data = data_frame_of_bots, x = X, bw_adjust=6, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'],  fill=False, common_norm=False, alpha=.6)\n","\n","#     ax.legend(loc='upper left')\n","#     g.set_ylabels(\"survival probability\")\n","\n","    \n","#     g.set_ylabels(\"survival probability\")\n","\n","#     sns.scatterplot(data = data_frame_of_bots, x = data_cols[44], y = data_cols[45], hue = 'Type', alpha = 0.4,   style = \"Type\")\n","#     g.legend(fontsize = 15, bbox_to_anchor= (1.03, 1), title=\"Delivery Type\", title_fontsize = 18, shadow = True, facecolor = 'white')    \n","\n","    plt.savefig(GAN_type + '_' + str(i) + 'contour.eps', dpi=600)\n","    \n","\n","    plt.show()\n","    plt.close()\n","#         plt.legend(loc='lower left', bbox_to_anchor= (0.0, 1.01), ncol=3, borderaxespad=0, frameon=False)\n","#     sns.kdeplot(data = data_frame_of_bots, x = data_cols[49], y = data_cols[50],  bw_adjust=6, fill = False, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","#     plt.show()\n","#     plt.close()\n","\n","#     sns.kdeplot(data = data_frame_of_bots, x = data_cols[52], y = data_cols[53],  bw_adjust=6, fill = False, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","#     plt.show()\n","#     plt.close()\n","\n","#     sns.kdeplot(data = data_frame_of_bots, x = data_cols[58], y = data_cols[59],  bw_adjust=6, fill = False, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","#     plt.show()\n","#     plt.close()\n","\n","#         plt.tight_layout()\n","#         sns.jointplot(data=data_frame_of_bots, x=data_cols[5], y=data_cols[6], hue=\"Type\", kind=\"kde\")\n","#         sns.displot(data=data_frame_of_bots, x=data_cols[j], kde=True, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","    \n","    #     plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)    \n","        \n","\n","    #     sns.displot(data = data_frame_of_bots, x = data_cols[5], kind = 'kde', hue=\"Type\")    \n","\n","\n","#     sns.scatterplot(data = data_frame_of_bots, x = data_cols[5], y = data_cols[6], hue = 'Type', alpha = 0.4,   style = \"Type\")\n","    \n","#     plt.legend(loc='lower left', bbox_to_anchor= (0.0, 1.01), ncol=3, borderaxespad=0, frameon=False)\n","#     plt.tight_layout()\n","#     sns.jointplot(data=data_frame_of_bots, x=data_cols[5], y=data_cols[6], hue=\"Type\", kind=\"kde\")\n","#     plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)    \n","#     plt.xlim(-.06, .06)\n","#     plt.ylim(-.05, .05)\n","\n","#     plt.show()\n","#     plt.close()    \n","\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-4a045d3bc2b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# For reloading after making changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spec__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkgpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"spec not found for the module {name!r}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# The module may have replaced itself in sys.modules!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: spec not found for the module 'header'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"iy1iDkpFrmE7"},"source":["# Data generated using accuracy weights\n","\n","\n","# real_bots_df = bots[X_cols].copy()\n","# real_bots_df['Type'] = 'Real Bots'\n","\n","# data_frame_of_bots = real_bots_df\n","\n","# classifiers = ['XGB', 'DT', 'NB', 'RF', 'LR', 'KNN']\n","\n","# for (j, i) in zip(classifiers, range(0, len(best_losses), 2)):\n","#     gan_bots_acc = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","#     gan_bots_acc['Type'] = j + '_GAN Bots(C2ST)'\n","    \n","# #     gan_bots_acc = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i+1], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","# #     gan_bots_acc['Type'] = j + '_GAN Bots(Acc)'\n","#     data_frame_of_bots = pd.concat([data_frame_of_bots, gan_bots_acc]).reset_index(drop=True).copy()\n","\n","\n","# sns.kdeplot(data = data_frame_of_bots, x = 'Total Length of Fwd Packet', y = 'Total Length of Bwd Packet',  bw_adjust=2, fill = False, hue = 'Type')\n","# plt.xlim(-.05, .09)\n","# plt.ylim(-.06, .07)\n","\n","\n","\n","# plt.show()\n","# plt.close(fig)\n","\n","\n","\n","\n","# # Data generated using recall weights\n","\n","\n","\n","# real_bots_df = bots[X_cols].copy()\n","# real_bots_df['Type'] = 'Real Bots'\n","\n","# data_frame_of_bots = real_bots_df\n","\n","# classifiers = ['XGB', 'DT', 'NB', 'RF', 'LR', 'KNN']\n","\n","# for (j, i) in zip(classifiers, range(0, len(best_losses), 2)):\n","#     gan_bots_acc = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","#     gan_bots_acc['Type'] = j + '_GAN Bots(Botshot)'\n","#     data_frame_of_bots = pd.concat([data_frame_of_bots, gan_bots_acc]).reset_index(drop=True).copy()\n","\n","# print(gan_bots_acc.shape)\n","# print(gan_bots_rcl.shape)\n","\n","# sns.kdeplot(data = data_frame_of_bots, x = 'Total Length of Fwd Packet', y = 'Total Length of Bwd Packet',  bw_adjust=2, fill = False, hue = 'Type')\n","# plt.xlim(-.05, .09)\n","# plt.ylim(-.06, .07)\n","\n","# plt.show()\n","# plt.close(fig)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"myF2tHj6rmE8"},"source":["<a id=\"Case7: Select Test Set\"><h1>Blackbox Attack [C2ST]</h1></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"eV_hwJiyrmE9"},"source":["if C2ST_BLACK_BOX_TEST:\n","    for i in range(10): # 10-folds testing\n","        # split data into train and test sets\n","        seed = i\n","        test_size = 0.3\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","        split_70_30 = True\n","\n","        print('Using Train set 70:30 split >>>>>>>')\n","        print(len(X_train), len(X_test), len(y_train), len(y_test))\n","\n","#============================================== REAL BOTS =================================================================================================\n","\n","        TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","        TRAIN_TRAFFIC['Label'] = y_train\n","\n","        BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","        BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","        print('bot samples in TRAIN_TRAFFIC: ' + str(BOT_COUNTS))  \n","        print('benign samples in TRAIN_TRAFFIC: ' + str(BENIGN_COUNTS))\n","\n","\n","        TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS ===============================================================================================\n","        REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","        BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","#============================================== Oversample bots for data balancing =======================================================================        \n","        if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","            df = REAL_BOTS.copy()\n","            DATA_SIZE = BENIGN_SAMPLES\n","\n","            for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                df = pd.concat([df, REAL_BOTS])\n","\n","            REAL_BOTS = df.copy()\n","            print(REAL_BOTS.shape)\n","            REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","     #============================================== Generate Labels =========================================================================================        \n","\n","            algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","            rows = len(algorithms)\n","            columns = 1\n","            fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                    constrained_layout=True)\n","\n","            for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                colors = np.clip(labels,-1,9)\n","                colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                plt.subplot(rows,columns,i*columns+1)\n","                plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                plt.title(name)\n","#============================================== Testing =================================================================================================        \n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = XGB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running XGB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = DT_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running DT ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = NB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running NB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number =RF_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running RF ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = LR_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running LR ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=LogisticRegression(max_iter=1000) )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = KNN_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running KNN ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Irk-QdXrmE-"},"source":["<a id=\"Case7: Select Test Set\"><h1>Blackbox Attack [BOTSHOT]</h1></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"jyWGboWbrmE_"},"source":["if BOTSHOT_BLACK_BOX_TEST:\n","    for i in range(10): # 10-folds testing\n","        # split data into train and test sets\n","        seed = i\n","        test_size = 0.3\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","        split_70_30 = True\n","\n","        print('Using Train set 70:30 split >>>>>>>')\n","        print(len(X_train), len(X_test), len(y_train), len(y_test))\n","\n","#============================================== REAL BOTS =================================================================================================\n","\n","        TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","        TRAIN_TRAFFIC['Label'] = y_train\n","\n","        BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","        BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","        print('bot samples in TRAIN_TRAFFIC: ' + str(BOT_COUNTS))  \n","        print('benign samples in TRAIN_TRAFFIC: ' + str(BENIGN_COUNTS))\n","\n","\n","        TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS ===============================================================================================\n","        REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","        BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","#============================================== Oversample bots for data balancing =======================================================================        \n","        if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","            df = REAL_BOTS.copy()\n","            DATA_SIZE = BENIGN_SAMPLES\n","\n","            for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                df = pd.concat([df, REAL_BOTS])\n","\n","            REAL_BOTS = df.copy()\n","            print(REAL_BOTS.shape)\n","            REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","     #============================================== Generate Labels =========================================================================================        \n","\n","            algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","            rows = len(algorithms)\n","            columns = 1\n","            fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                    constrained_layout=True)\n","\n","            for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                colors = np.clip(labels,-1,9)\n","                colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                plt.subplot(rows,columns,i*columns+1)\n","                plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                plt.title(name)\n","#============================================== Testing =================================================================================================        \n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = XGB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running XGB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = DT_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running DT ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = NB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running NB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number =RF_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running RF ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = LR_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running LR ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=LogisticRegression(max_iter=1000) )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = KNN_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running KNN ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H_YCjpxTrmFB"},"source":["<a id=\"Case3: Select Test Set\"><h1>Visually Test Overlapping</h1>"]},{"cell_type":"code","metadata":{"id":"mdNKo1j8rmFB"},"source":["if VISUAL_TEST_OVERLAPPING:\n","\n","    axarr = [[]]*len(X_cols)\n","    columns = 4\n","    rows = int( np.ceil( len(X_cols) / columns ) )\n","    f, fig = plt.subplots( figsize=(columns*2.5, rows*2) )\n","\n","    f.suptitle('Data Distributions by Feature and Label', size=16)\n","\n","    for i, col in enumerate(X_cols[:]):\n","        axarr[i] = plt.subplot2grid( (int(rows), int(columns)), (int(i//columns), int(i%columns)) )\n","\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 0, col ] , label=['Normal'], color=('#009933'), alpha=0.6,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 1, col ] , label=['Real Bot'], color=['#FF0000'], alpha=0.5,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 2, col ] , label=['GAN Bot'], color=['#0000ff'], alpha=0.4,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","\n","\n","\n","\n","        axarr[i].set_xlabel(col, size=12)\n","    #     axarr[i].set_ylim([0,1])\n","        axarr[i].tick_params(axis='both', labelsize=10)\n","        if i == 0: \n","            legend = axarr[i].legend()\n","            legend.get_frame().set_facecolor('white')\n","        if i%4 != 0 : \n","            axarr[i].tick_params(axis='y', left=True, labelleft=True)\n","        else:\n","            axarr[i].set_ylabel('Fraction',size=12)\n","\n","    plt.tight_layout(rect=[0,0,1,0.95]) # xmin, ymin, xmax, ymax\n","    # plt.savefig('plots/Engineered_Data_Distributions.png')\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fbrwEH_trmFB"},"source":["import classifiers\n","import importlib\n","importlib.reload(classifiers) # For reloading after making changes\n","from classifiers import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zxvtAejErmFC"},"source":["<a id=\"Case7: Select Test Set\"><h1>GAN [DATA AUG: C2ST]</h1></a>"]},{"cell_type":"code","metadata":{"id":"QXlKSnKsrmFD"},"source":["GAN_aug_accu_list = []\n","GAN_aug_rcl_list = []\n","GAN_aug_prec_list = []\n","GAN_aug_f1_list = []\n","\n","del GAN_aug_accu_list \n","del GAN_aug_rcl_list \n","del GAN_aug_prec_list \n","del GAN_aug_f1_list\n","\n","GAN_aug_accu_list = []\n","GAN_aug_rcl_list = []\n","GAN_aug_prec_list = []\n","GAN_aug_f1_list = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"9Nc-HeHIrmFD"},"source":["if ACCU_EVAL_TEST:  \n","    if USE_ONLY_TRAIN_SET:\n","\n","        for k in range(10): # 10-folds testing\n","            \n","            # split data into train and test sets\n","            seed = k\n","            test_size = 0.3\n","            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","            split_70_30 = True\n","\n","            print('Using Train set 70:30 split >>>>>>>')\n","    #============================================== Assign Values ==========================================================================================\n","            TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","            TRAIN_TRAFFIC['Label'] = y_train\n","\n","            BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","            BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","            print('bot samples: ' + str(BOT_COUNTS))  \n","            print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","            TRAIN_TRAFFIC.columns = training_data.columns\n","            \n","            REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","            BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","            \n","            if BALANCE_THE_DATASET:\n","                df = REAL_BOTS.copy()\n","\n","                for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                    df = pd.concat([df, REAL_BOTS]).copy()\n","                    \n","                df = pd.concat([df, REAL_BOTS[0: BENIGN_COUNTS%BOT_COUNTS]]).copy() # add the remaining bots\n","                    \n","                print(df.shape)\n","                \n","                df = df[0:df.shape[0] - 2 * (REAL_BOTS.shape[0])].copy() # We need to balance data so the labels will be generated of this size.We subtracted REAL_BOTS.shape[0] twice in order to balance bots with normal data.\n","                BIG_REAL_BOTS = df.copy()\n","\n","                print(df.shape)\n","    #============================================== Oversample bots for data balancing =======================================================================        \n","            if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","\n","                BIG_REAL_BOTS_WITHOUT_LABEL = BIG_REAL_BOTS[BIG_REAL_BOTS.columns[:-1]]      \n","         #============================================== Generate Labels =========================================================================================        \n","\n","                algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","                rows = len(algorithms)\n","                columns = 1\n","                fig, ax = plt.subplots(3, 2, figsize=(5, 3), constrained_layout=True)\n","                plt.xlim(0, 1)\n","\n","\n","                for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                    labels = algorithm(*args, **kwds).fit_predict(BIG_REAL_BOTS_WITHOUT_LABEL)\n","                    colors = np.clip(labels,-1,9)\n","                    colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                    plt.subplot(rows,columns,i*columns+1)\n","                    plt.scatter(BIG_REAL_BOTS_WITHOUT_LABEL[X_cols[0]], BIG_REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                    plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                    plt.title(name)\n","                    \n","    #============================================== Testing =================================================================================================        \n","            print(i)    \n","            \n","            GAN_BOTS_XGB_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = XGB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","            X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_XGB_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'XGB')\n","            print('Running XGB ...')     \n","            clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","            \n","            if USE_ALL_CLASSIFIERS :\n","                \n","                GAN_BOTS_DT_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = DT_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_DT_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'DT')\n","                print('Running DT ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","                GAN_BOTS_NB_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = NB_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_NB_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'NB')\n","                print('Running NB ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","                GAN_BOTS_RF_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = RF_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_RF_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'RF')\n","                print('Running RF ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","                GAN_BOTS_LR_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = LR_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_LR_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'LR')\n","                print('Running LR ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list,  clf=LogisticRegression(max_iter=1000) )   \n","\n","                GAN_BOTS_KNN_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = KNN_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_KNN_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'KNN')\n","                print('Running KNN ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lLYrGV4xrmFF"},"source":["<a id=\"Case7: Select Test Set\"><h1>GAN [Evaluation: ACCURACY with data generated on single classfier weight of Generator]</h1></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"eOGHjt6FrmFF"},"source":["if SINGLE_WEIGHT_CLASSIFIER_TEST_C2ST:\n","\n","    GAN_aug_accu_list = []\n","    GAN_aug_rcl_list = []\n","    GAN_aug_prec_list = []\n","    GAN_aug_f1_list = []\n","\n","    del GAN_aug_accu_list \n","    del GAN_aug_rcl_list \n","    del GAN_aug_prec_list \n","    del GAN_aug_f1_list\n","\n","    GAN_aug_accu_list = []\n","    GAN_aug_rcl_list = []\n","    GAN_aug_prec_list = []\n","    GAN_aug_f1_list = []\n","\n","    if ACCU_EVAL_TEST:  \n","        if USE_ONLY_TRAIN_SET:\n","\n","            for k in range(10): # 10-folds testing\n","                # split data into train and test sets\n","                seed = k\n","                test_size = 0.3\n","                X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","                split_70_30 = True\n","\n","                print('Using Train set 70:30 split >>>>>>>')\n","        #============================================== Assign Values ==========================================================================================\n","                TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","                TRAIN_TRAFFIC['Label'] = y_train\n","\n","                BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","                BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","                print('bot samples: ' + str(BOT_COUNTS))  \n","                print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","                TRAIN_TRAFFIC.columns = training_data.columns\n","        #============================================== REAL BOTS ===============================================================================================\n","                REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","                BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","        #============================================== Oversample bots for data balancing =======================================================================        \n","                if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","\n","                    df = REAL_BOTS.copy()\n","                    DATA_SIZE = BENIGN_SAMPLES\n","\n","                    for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                        df = pd.concat([df, REAL_BOTS])\n","\n","                    REAL_BOTS = df.copy()\n","                    print(REAL_BOTS.shape)\n","                    REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","             #============================================== Generate Labels =========================================================================================        \n","\n","                    algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","                    rows = len(algorithms)\n","                    columns = 1\n","                    fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                            constrained_layout=True)\n","\n","                    for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                        labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                        colors = np.clip(labels,-1,9)\n","                        colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                        plt.subplot(rows,columns,i*columns+1)\n","                        plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                        plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                        plt.title(name)\n","        #============================================== Testing =================================================================================================        \n","\n","                classifiers = [XGBClassifier(), DecisionTreeClassifier(), GaussianNB(), RandomForestClassifier(n_estimators=100), LogisticRegression(max_iter=1000), KNeighborsClassifier(n_neighbors=5)]\n","\n","                for l in  range(0, len(best_losses), 2):\n","\n","                    GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = best_losses[l], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = REAL_BOTS.shape[0])\n","                    print(GAN_BOTS.shape)\n","                    #plot_kde(REAL_BOTS, GAN_BOTS, BENIGN_SAMPLES, with_class = True)    \n","                    X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS, training_data.columns)\n","                    print('Data generating using ' + str(i))\n","\n","                    for j in classifiers:\n","\n","                        print('Running ' + str(j) )    \n","                        clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=j )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KhhSaZQJrmFG"},"source":["<a id=\"Case7: Select Test Set\"><h1>GAN [Evaluation: RECALL with data generated on single classfier weight of Generator]</h1></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"8os4ONqArmFH"},"source":["if SINGLE_WEIGHT_CLASSIFIER_TEST_PROPOSED_METHODOLOGY:\n","\n","    RCL_GAN_aug_accu_list = []\n","    RCL_GAN_aug_rcl_list = []\n","    RCL_GAN_aug_prec_list = []\n","    RCL_GAN_aug_f1_list = []\n","\n","    del RCL_GAN_aug_accu_list \n","    del RCL_GAN_aug_rcl_list \n","    del RCL_GAN_aug_prec_list \n","    del RCL_GAN_aug_f1_list\n","\n","    RCL_GAN_aug_accu_list = []\n","    RCL_GAN_aug_rcl_list = []\n","    RCL_GAN_aug_prec_list = []\n","    RCL_GAN_aug_f1_list = []\n","\n","    if ACCU_EVAL_TEST:  \n","        if USE_ONLY_TRAIN_SET:\n","\n","            for k in range(10): # 10-folds testing\n","                # split data into train and test sets\n","                seed = k\n","                test_size = 0.3\n","                X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","                split_70_30 = True\n","\n","                print('Using Train set 70:30 split >>>>>>>')\n","        #============================================== Assign Values ==========================================================================================\n","                TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","                TRAIN_TRAFFIC['Label'] = y_train\n","\n","                BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","                BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","                print('bot samples: ' + str(BOT_COUNTS))  \n","                print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","                TRAIN_TRAFFIC.columns = training_data.columns\n","        #============================================== REAL BOTS ===============================================================================================\n","                REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","                BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","        #============================================== Oversample bots for data balancing =======================================================================        \n","                if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","\n","                    df = REAL_BOTS.copy()\n","                    DATA_SIZE = BENIGN_SAMPLES\n","\n","                    for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                        df = pd.concat([df, REAL_BOTS])\n","\n","                    REAL_BOTS = df.copy()\n","                    print(REAL_BOTS.shape)\n","                    REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","             #============================================== Generate Labels =========================================================================================        \n","\n","                    algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","                    rows = len(algorithms)\n","                    columns = 1\n","                    fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                            constrained_layout=True)\n","\n","                    for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                        labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                        colors = np.clip(labels,-1,9)\n","                        colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                        plt.subplot(rows,columns,i*columns+1)\n","                        plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                        plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                        plt.title(name)\n","        #============================================== Testing =================================================================================================        \n","\n","                classifiers = [XGBClassifier(), DecisionTreeClassifier(), GaussianNB(), RandomForestClassifier(n_estimators=100), LogisticRegression(max_iter=1000), KNeighborsClassifier(n_neighbors=5)]\n","\n","                for l in  range(1, len(best_losses), 2):\n","\n","                    GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = best_losses[l], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = REAL_BOTS.shape[0] * 2)\n","                    print(GAN_BOTS.shape)\n","                    #plot_kde(REAL_BOTS, GAN_BOTS, BENIGN_SAMPLES, with_class = True)    \n","                    X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS, training_data.columns)\n","                    print('Data generating using ' + str(i))\n","\n","                    for j in classifiers:\n","\n","                        print('Running ' + str(j) )    \n","                        clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=j )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NOjz1kt2rmFI"},"source":["<a id=\"Case7: Select Test Set\"><h1>GAN [Evaluation: BOTSHOT]</h1></a>"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ejqoIj6grmFJ"},"source":["RCL_GAN_aug_accu_list = []\n","RCL_GAN_aug_rcl_list = []\n","RCL_GAN_aug_prec_list = []\n","RCL_GAN_aug_f1_list = []\n","\n","del RCL_GAN_aug_accu_list \n","del RCL_GAN_aug_rcl_list \n","del RCL_GAN_aug_prec_list \n","del RCL_GAN_aug_f1_list\n","\n","RCL_GAN_aug_accu_list = []\n","RCL_GAN_aug_rcl_list = []\n","RCL_GAN_aug_prec_list = []\n","RCL_GAN_aug_f1_list = []\n","\n","\n","if RCL_EVAL_TEST:  \n","    if USE_ONLY_TRAIN_SET:\n","\n","        for k in range(10): # 10-folds testing\n","            \n","            # split data into train and test sets\n","            seed = k\n","            test_size = 0.3\n","            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","            split_70_30 = True\n","\n","            print('Using Train set 70:30 split >>>>>>>')\n","    #============================================== Assign Values ==========================================================================================\n","            TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","            TRAIN_TRAFFIC['Label'] = y_train\n","\n","            BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","            BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","            print('bot samples: ' + str(BOT_COUNTS))  \n","            print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","            TRAIN_TRAFFIC.columns = training_data.columns\n","            \n","            REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","            BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","            \n","            if BALANCE_THE_DATASET:\n","                df = REAL_BOTS.copy()\n","\n","                for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                    df = pd.concat([df, REAL_BOTS]).copy()\n","                    \n","                df = pd.concat([df, REAL_BOTS[0: BENIGN_COUNTS%BOT_COUNTS]]).copy() # add the remaining bots\n","                    \n","                print(df.shape)\n","                \n","                df = df[0:df.shape[0] - 2 * (REAL_BOTS.shape[0])].copy() # We need to balance data so the labels will be generated of this size.We subtracted REAL_BOTS.shape[0] twice in order to balance bots with normal data.\n","                BIG_REAL_BOTS = df.copy()\n","\n","                print(df.shape)\n","    #============================================== Oversample bots for data balancing =======================================================================        \n","            if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","\n","                BIG_REAL_BOTS_WITHOUT_LABEL = BIG_REAL_BOTS[BIG_REAL_BOTS.columns[:-1]]      \n","         #============================================== Generate Labels =========================================================================================        \n","\n","                algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","                rows = len(algorithms)\n","                columns = 1\n","                fig, ax = plt.subplots(3, 2, figsize=(5, 3), constrained_layout=True)\n","                plt.xlim(0, 1)\n","\n","\n","                for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                    labels = algorithm(*args, **kwds).fit_predict(BIG_REAL_BOTS_WITHOUT_LABEL)\n","                    colors = np.clip(labels,-1,9)\n","                    colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                    plt.subplot(rows,columns,i*columns+1)\n","                    plt.scatter(BIG_REAL_BOTS_WITHOUT_LABEL[X_cols[0]], BIG_REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                    plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                    plt.title(name)\n","                    \n","    #============================================== Testing =================================================================================================        \n","            print(i)    \n","            \n","            GAN_BOTS_XGB_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = XGB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","            X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_XGB_RCL_WEIGHT, training_data.columns)\n","            print('Running XGB ...')     \n","            clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=XGBClassifier() )   \n","                \n","            if USE_ALL_CLASSIFIERS :\n","\n","                GAN_BOTS_DT_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = DT_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_DT_RCL_WEIGHT, training_data.columns)\n","                print('Running DT ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","                GAN_BOTS_NB_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = NB_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_NB_RCL_WEIGHT, training_data.columns)\n","                print('Running NB ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","                GAN_BOTS_RF_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = RF_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_RF_RCL_WEIGHT, training_data.columns)\n","                print('Running RF ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","                GAN_BOTS_LR_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = LR_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_LR_RCL_WEIGHT, training_data.columns)\n","                print('Running LR ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list,  clf=LogisticRegression(max_iter=1000) )   \n","\n","                GAN_BOTS_KNN_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = KNN_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_KNN_RCL_WEIGHT, training_data.columns)\n","                print('Running KNN ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X779KEcGrmFK"},"source":["<a id=\"Case7: Select Test Set\"><h1>Blackbox Attack AFTER GAN TRAINING[C2ST]</h1></a>"]},{"cell_type":"code","metadata":{"id":"fnBPk0IkrmFK"},"source":["if C2ST_BLACK_BOX_TEST_AFTER_GAN_TRAINING:\n","    for i in range(10): # 10-folds testing\n","        # split data into train and test sets\n","        seed = i\n","        test_size = 0.3\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","        split_70_30 = True\n","\n","        print('Using Train set 70:30 split >>>>>>>')\n","        print(len(X_train), len(X_test), len(y_train), len(y_test))\n","\n","#============================================== REAL BOTS =================================================================================================\n","\n","        TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","        TRAIN_TRAFFIC['Label'] = y_train\n","\n","        BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","        BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","        print('bot samples in TRAIN_TRAFFIC: ' + str(BOT_COUNTS))  \n","        print('benign samples in TRAIN_TRAFFIC: ' + str(BENIGN_COUNTS))\n","\n","\n","        TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS ===============================================================================================\n","        REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","        BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","#============================================== Oversample bots for data balancing =======================================================================        \n","        if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","            df = REAL_BOTS.copy()\n","            DATA_SIZE = BENIGN_SAMPLES\n","\n","            for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                df = pd.concat([df, REAL_BOTS])\n","\n","            REAL_BOTS = df.copy()\n","            print(REAL_BOTS.shape)\n","            REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","     #============================================== Generate Labels =========================================================================================        \n","\n","            algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","            rows = len(algorithms)\n","            columns = 1\n","            fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                    constrained_layout=True)\n","\n","            for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                colors = np.clip(labels,-1,9)\n","                colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                plt.subplot(rows,columns,i*columns+1)\n","                plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                plt.title(name)\n","#============================================== Testing =================================================================================================        \n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = XGB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running XGB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","\n","        if USE_ALL_CLASSIFIERS :\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = DT_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running DT ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = NB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running NB ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number =RF_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running RF ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = LR_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running LR ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=LogisticRegression(max_iter=1000) )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = KNN_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running KNN ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwUZ_xZErmFL"},"source":["<a id=\"Case7: Select Test Set\"><h1>Blackbox Attack AFTER GAN TRAINING[BOTSHOT]</h1></a>"]},{"cell_type":"code","metadata":{"id":"pQdFxrHzrmFM"},"source":["if BOTSHOT_BLACK_BOX_TEST_AFTER_GAN_TRAINING:\n","    for i in range(10): # 10-folds testing\n","        # split data into train and test sets\n","        seed = i\n","        test_size = 0.3\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","        split_70_30 = True\n","\n","        print('Using Train set 70:30 split >>>>>>>')\n","        print(len(X_train), len(X_test), len(y_train), len(y_test))\n","\n","#============================================== REAL BOTS =================================================================================================\n","\n","        TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","        TRAIN_TRAFFIC['Label'] = y_train\n","\n","        BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","        BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","        print('bot samples in TRAIN_TRAFFIC: ' + str(BOT_COUNTS))  \n","        print('benign samples in TRAIN_TRAFFIC: ' + str(BENIGN_COUNTS))\n","\n","\n","        TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS ===============================================================================================\n","        REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","        BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","#============================================== Oversample bots for data balancing =======================================================================        \n","        if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","            df = REAL_BOTS.copy()\n","            DATA_SIZE = BENIGN_SAMPLES\n","\n","            for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                df = pd.concat([df, REAL_BOTS])\n","\n","            REAL_BOTS = df.copy()\n","            print(REAL_BOTS.shape)\n","            REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","     #============================================== Generate Labels =========================================================================================        \n","\n","            algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","            rows = len(algorithms)\n","            columns = 1\n","            fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                    constrained_layout=True)\n","\n","            for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                colors = np.clip(labels,-1,9)\n","                colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                plt.subplot(rows,columns,i*columns+1)\n","                plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                plt.title(name)\n","#============================================== Testing =================================================================================================        \n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = XGB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running XGB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","            \n","        if USE_ALL_CLASSIFIERS :\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = DT_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running DT ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = NB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running NB ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number =RF_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running RF ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = LR_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running LR ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=LogisticRegression(max_iter=1000) )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = KNN_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running KNN ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Qx2D4pjrmFO"},"source":["<a id=\"DATA Generation for Others\"><h1>DATA GENERATION for Others</h1></a>"]},{"cell_type":"code","metadata":{"id":"yE9BH2pqrmFO"},"source":["if GENERATE_OTHERS_DATA:\n","    X_train = training_data[X_cols].values\n","    y_train = training_data[y_cols].values\n","    if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","        df = REAL_BOTS.copy()\n","        DATA_SIZE = BENIGN_SAMPLES\n","\n","        for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","            df = pd.concat([df, REAL_BOTS])\n","\n","        REAL_BOTS = df.copy()\n","        print(REAL_BOTS.shape)\n","        REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n"," #============================================== Generate Labels =========================================================================================        \n","\n","        algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","        rows = len(algorithms)\n","        columns = 1\n","        fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                constrained_layout=True)\n","\n","        for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","            labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","            colors = np.clip(labels,-1,9)\n","            colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","            plt.subplot(rows,columns,i*columns+1)\n","            plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","            plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","            plt.title(name)\n","\n","    MALICIOUS_DATA = bots.copy() # Real Botnets\n","    \n","    print(MALICIOUS_DATA.shape)\n","\n","    WEIGHT = generate_gan_data(MALICIOUS_DATA, labels, weight_or_epoch_number = XGB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = MALICIOUS_DATA.shape[0])\n","    augment_bots(X_train, y_train, WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = DATA_SET)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wVUk7jJurmFO"},"source":["training_data = pd.read_csv (DATA_SET + '_GAN_AUG_DATA_SET.csv', low_memory=False)\n","\n","print('Dataset Imported: ' + DATA_SET)\n","print('Training set: '+ str(training_data.shape))\n","\n","training_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7MOK_DcrmFP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xi1Xto4urmFP"},"source":[""],"execution_count":null,"outputs":[]}]}