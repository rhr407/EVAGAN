{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","celltoolbar":"Slideshow","colab":{"name":"EVAGAN_CV.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"0754585e5bea998e5d67e8f88be1e2a4051f453a7d5aedf516d053743049d686"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CRWaG6qPWj1T"},"source":["<a id=\"CGAN\"><h1>Import Header</h1></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adrd84AgicLV","executionInfo":{"status":"ok","timestamp":1631221316669,"user_tz":-300,"elapsed":1109,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"9ec36649-3ec6-4d4e-828c-b73c10b6ff84"},"source":["from google.colab import drive \n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/PhD/Development/code/Current/EVAGAN"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/PhD/Development/code/Current/EVAGAN\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mTwKRaEVjJ8c","executionInfo":{"status":"ok","timestamp":1631221320832,"user_tz":-300,"elapsed":3521,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"35d0cbd9-b151-4e2b-e116-000b93902e7b"},"source":["!pip install smote_variants"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: smote_variants in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from smote_variants) (2.6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from smote_variants) (1.1.5)\n","Requirement already satisfied: statistics in /usr/local/lib/python3.7/dist-packages (from smote_variants) (1.0.3.5)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from smote_variants) (2019.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from smote_variants) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from smote_variants) (1.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from smote_variants) (1.0.1)\n","Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from smote_variants) (1.19.5)\n","Requirement already satisfied: minisom in /usr/local/lib/python3.7/dist-packages (from smote_variants) (2.2.9)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from smote_variants) (2.6.0)\n","Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->smote_variants) (2021.3.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->smote_variants) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->smote_variants) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->smote_variants) (1.15.0)\n","Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.7/dist-packages (from statistics->smote_variants) (0.17.1)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (2.6.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (0.4.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (3.1.0)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (2.6.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (1.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (3.17.3)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (3.3.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (0.2.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (1.1.2)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (0.12.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (1.39.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (1.12)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (1.12.1)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (3.7.4.3)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (5.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (1.6.3)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote_variants) (0.37.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->smote_variants) (1.5.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->smote_variants) (1.34.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->smote_variants) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->smote_variants) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->smote_variants) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->smote_variants) (1.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->smote_variants) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->smote_variants) (0.4.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->smote_variants) (57.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->smote_variants) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->smote_variants) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->smote_variants) (4.2.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->smote_variants) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->smote_variants) (4.6.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->smote_variants) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->smote_variants) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->smote_variants) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->smote_variants) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->smote_variants) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->smote_variants) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow->smote_variants) (3.5.0)\n"]}]},{"cell_type":"code","metadata":{"id":"ZlXu5pxhWj1b","scrolled":true,"executionInfo":{"status":"ok","timestamp":1631221326182,"user_tz":-300,"elapsed":5359,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}}},"source":["import importlib\n","import header\n","\n","importlib.reload(header) # For reloading after making changes\n","from header import *"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"aQkaphklFIYW"},"source":["<a id=\"CGAN\"><h1>Select GAN and Dataset and Flags</h1></a>"]},{"cell_type":"code","metadata":{"id":"kPfnVUMHWj1h","executionInfo":{"status":"ok","timestamp":1631221326185,"user_tz":-300,"elapsed":102,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}}},"source":["# GAN_type = 'GAN'\n","# GAN_type = 'CGAN'\n","# GAN_type = 'WGAN'\n","# GAN_type = 'WCGAN'\n","# GAN_type = 'EVAGAN'\n","# GAN_type = 'ACGAN_CV'\n","GAN_type = 'EVAGAN_CV'\n","\n","\n","DATA_SET = 'ISCX-2014'\n","# DATA_SET = 'CIC-2017'\n","# DATA_SET = 'CIC-2018'\n","# DATA_SET = 'UNSW_BotIoT'\n","\n","\n","# DATA_SET = 'Drebin'\n","\n","# DATA_SET = 'Darknet'"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4zsYaqGjWj1j"},"source":["<a id=\"GPU Settings\"><h2>Set Flags</h2></a>"]},{"cell_type":"code","metadata":{"id":"S1cf7rM3Wj1k","executionInfo":{"status":"ok","timestamp":1631221326188,"user_tz":-300,"elapsed":101,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}}},"source":["begin_from_start = 0\n","take_chunk = 0\n","required_epochs = 150\n","\n","DISPLAY_FEATURES = 0\n","EVALUATION_PARAMETER = 'Accuracy'\n","SAVE_ONLY_BOT_DATA = 0\n","USE_KMEANS_FOR_CLASSIFICATION = 1\n","\n","BALANCE_THE_DATASET = 1\n","\n","labels =[]\n","\n","USE_ONLY_TRAIN_SET = 1\n","\n","USE_ALL_CLASSIFIERS = 0\n","\n","ACCU_EVAL_TEST = 0\n","RCL_EVAL_TEST = 0\n","\n","VISUAL_TEST_OVERLAPPING = 1\n","\n","CSV_ONE_BOT = 0\n","\n","VIEW_ALL_BOTS = 0\n","\n","CTU_NERIS = 0\n","\n","SINGLE_WEIGHT_CLASSIFIER_TEST_C2ST = 0\n","SINGLE_WEIGHT_CLASSIFIER_TEST_PROPOSED_METHODOLOGY = 0\n","\n","C2ST_BLACK_BOX_TEST = 0\n","BOTSHOT_BLACK_BOX_TEST = 0\n","\n","C2ST_BLACK_BOX_TEST_AFTER_GAN_TRAINING = 0\n","BOTSHOT_BLACK_BOX_TEST_AFTER_GAN_TRAINING = 0\n","\n","GENERATE_OTHERS_DATA = 1"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gbFYC_WQWj1n"},"source":["<a id=\"CGAN\"><h1>Set Paths</h1></a>"]},{"cell_type":"code","metadata":{"id":"8Al8rt2iWj1p","executionInfo":{"status":"ok","timestamp":1631221326190,"user_tz":-300,"elapsed":98,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}}},"source":["MAIN_CODE_PATH = os.getcwd()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrizUpKsYxel","executionInfo":{"status":"ok","timestamp":1631221326191,"user_tz":-300,"elapsed":96,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}}},"source":["DATA_SET_PATH = MAIN_CODE_PATH + '/Dataset/' +  DATA_SET + '/'\n","CACHE_PATH = MAIN_CODE_PATH + '/cache/' + GAN_type + '/'\n","FIGS_PATH = MAIN_CODE_PATH  + '/figs/' + GAN_type + '/'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yT1YS8U9Wj1t","scrolled":true,"executionInfo":{"status":"ok","timestamp":1631221326199,"user_tz":-300,"elapsed":102,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"dc194ab6-de42-48a8-ec3c-17e9107c0285"},"source":["print(DATA_SET_PATH)\n","print(CACHE_PATH)\n","print(FIGS_PATH)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/PhD/Development/code/Current/EVAGAN/Dataset/ISCX-2014/\n","/content/drive/My Drive/PhD/Development/code/Current/EVAGAN/cache/EVAGAN_CV/\n","/content/drive/My Drive/PhD/Development/code/Current/EVAGAN/figs/EVAGAN_CV/\n"]}]},{"cell_type":"markdown","metadata":{"id":"IwGuWbiSWj1y"},"source":["<a id=\"GPU Settings\"><h2>Check Available GPUs</h2></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwQXSblnWj10","executionInfo":{"status":"ok","timestamp":1631221326203,"user_tz":-300,"elapsed":101,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"479fd8c9-f070-4c7a-a8a5-e49bf9b8453b"},"source":["import tensorflow as tf\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZzSPR7q5Wj11"},"source":["<a id=\"GPU Settings\"><h2>Import Dataset</h2></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0MQAWmiWj12","executionInfo":{"status":"ok","timestamp":1631221326207,"user_tz":-300,"elapsed":93,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"33c4aa67-1c51-4734-bb52-934da0ea98f1"},"source":["%cd $DATA_SET_PATH\n","!ls"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/PhD/Development/code/Current/EVAGAN/Dataset/ISCX-2014\n"," __AUG_DATA_SET.csv\n"," best_losses.csv\n"," CGAN_0contour.eps\n"," CGAN_10contour.eps\n"," CGAN_2contour.eps\n"," CGAN_4contour.eps\n"," CGAN_6contour.eps\n"," CGAN_8contour.eps\n"," CGAN_data_frame_of_bots_0.csv\n"," CGAN_data_frame_of_bots_10.csv\n"," CGAN_data_frame_of_bots_2.csv\n"," CGAN_data_frame_of_bots_4.csv\n"," CGAN_data_frame_of_bots_6.csv\n"," CGAN_data_frame_of_bots_8.csv\n"," GAN_0contour.eps\n"," GAN_10contour.eps\n"," GAN_2contour.eps\n"," GAN_4contour.eps\n"," GAN_6contour.eps\n"," GAN_8contour.eps\n"," GAN_data_frame_of_bots_0.csv\n"," GAN_data_frame_of_bots_10.csv\n"," GAN_data_frame_of_bots_2.csv\n"," GAN_data_frame_of_bots_4.csv\n"," GAN_data_frame_of_bots_6.csv\n"," GAN_data_frame_of_bots_8.csv\n"," Husnain_GAN_AUG_DATA_SET.csv\n"," ISCX_Botnet-Testing.pcap_Flow.csv\n","'ISCX_Botnet-Testing.pcap_Flow.csv_(Preprocessed).csv'\n","'ISCX_Botnet-Testing.pcap_Flow.csv_VIRUT_(Preprocessed).csv'\n"," ISCX_Botnet-Training.pcap_Flow.csv\n","'ISCX_Botnet-Training.pcap_Flow.csv_(Preprocessed).csv'\n","'ISCX_Botnet-Training.pcap_Flow.csv_VIRUT_(Preprocessed).csv'\n"," _pred_Normal_or_Bot_0.csv\n"," _pred_Normal_or_Bot_1.csv\n"," shuffled_T_B.csv\n"," T.csv\n"," XGB_GAN_AUG_DATA_SET.csv\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIJpUfZdWj15","scrolled":false,"executionInfo":{"status":"ok","timestamp":1631221331101,"user_tz":-300,"elapsed":4968,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"1bd9cb8a-86c3-4a6f-d3fa-56758ae9d4da"},"source":["if begin_from_start:        \n","\n","    if DATA_SET == 'ISCX-2014':\n","        training_data = prepare_ISCX_2014_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'ISCX_Botnet-Training.pcap_Flow.csv')\n","        testing_data = prepare_ISCX_2014_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'ISCX_Botnet-Testing.pcap_Flow.csv') \n","    \n","    elif DATA_SET == 'CIC-2017':\n","        training_data = prepare_cic_2017_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'CIC_Friday_bot.csv')\n","        testing_data = prepare_cic_2017_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'CIC_Friday_bot.csv')\n","        \n","    elif DATA_SET == 'CIC-2018':\n","        training_data = prepare_cic_2018_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv')\n","        testing_data = prepare_cic_2018_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv')\n","        \n","    elif DATA_SET == 'UNSW_BotIoT':\n","        training_data = prepare_UNSW_IoT(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'UNSW_2018_IoT_Botnet_Final_10_best_Training.csv')\n","        testing_data = prepare_UNSW_IoT(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'UNSW_2018_IoT_Botnet_Final_10_best_Testing.csv')\n","        \n","    elif DATA_SET == 'Darknet':\n","        training_data = prepare_DARKNET_2020_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'Darknet.csv')\n","        testing_data = prepare_DARKNET_2020_data(PATH = DATA_SET_PATH, INPUT_FILE_NAME = r'Darknet.csv')\n","        \n","        \n","\n","    print('Dataset preprocessed: ' + DATA_SET)\n","    \n","else:\n","\n","    if DATA_SET == 'ISCX-2014':\n","        INPUT_TRAINING_FILE_NAME = r'ISCX_Botnet-Training.pcap_Flow.csv_VIRUT'\n","        INPUT_TESTING_FILE_NAME = r'ISCX_Botnet-Testing.pcap_Flow.csv_VIRUT'\n","        \n","    elif DATA_SET == 'CIC-2017':\n","        INPUT_TRAINING_FILE_NAME = r'CIC_Friday_bot.csv'\n","        INPUT_TESTING_FILE_NAME = r'CIC_Friday_bot.csv'\n","        \n","    elif DATA_SET == 'CIC-2018':\n","        INPUT_TRAINING_FILE_NAME = r'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv'\n","        INPUT_TESTING_FILE_NAME = r'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv'\n","        \n","    elif DATA_SET == 'BoT-IoT':\n","        INPUT_TRAINING_FILE_NAME = r'UNSW_2018_IoT_Botnet_Final_10_best_Training.csv'\n","        INPUT_TESTING_FILE_NAME = r'UNSW_2018_IoT_Botnet_Final_10_best_Testing.csv'\n","        \n","    elif DATA_SET == 'Drebin':\n","        INPUT_TRAINING_FILE_NAME = r'Drebin_API_Dataset.csv'\n","        INPUT_TESTING_FILE_NAME = r'Drebin_API_Dataset.csv'\n","        \n","    elif DATA_SET == 'Darknet':\n","        INPUT_TRAINING_FILE_NAME = r'Darknet.csv'\n","        INPUT_TESTING_FILE_NAME = r'Darknet.csv'\n","\n","    training_data = pd.read_csv (INPUT_TRAINING_FILE_NAME + '_(Preprocessed).csv', low_memory=False)\n","    training_data= training_data.drop(['Unnamed: 0'], axis=1)\n","    \n","    testing_data = pd.read_csv (INPUT_TESTING_FILE_NAME + '_(Preprocessed).csv', low_memory=False)\n","    testing_data= testing_data.drop(['Unnamed: 0'], axis=1) \n","    \n","    print('Dataset Imported: ' + DATA_SET)\n","    print('Training set: '+ str(training_data.shape))\n","    print('Testng set: '+ str(training_data.shape))\n","    \n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Imported: ISCX-2014\n","Training set: (248677, 61)\n","Testng set: (248677, 61)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eg83hsWRWj16","executionInfo":{"status":"ok","timestamp":1631221331759,"user_tz":-300,"elapsed":681,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"1a176ae7-c216-4db8-a280-d6026067534e"},"source":["training_data = training_data.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\").reset_index(drop=True)\n","print(training_data.describe())"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["       Flow Duration  Total Fwd Packet  ...      Idle Min          Label\n","count  248677.000000     248677.000000  ...  2.486770e+05  248677.000000\n","mean        0.113036          0.000844  ...  4.141199e-01       0.992971\n","std         0.252565          0.010604  ...  4.799477e-01       0.083545\n","min         0.000000          0.000000  ...  0.000000e+00       0.000000\n","25%         0.000005          0.000067  ...  0.000000e+00       1.000000\n","50%         0.004006          0.000133  ...  1.000000e-08       1.000000\n","75%         0.058283          0.000200  ...  9.715268e-01       1.000000\n","max         1.000000          1.000000  ...  1.000000e+00       1.000000\n","\n","[8 rows x 61 columns]\n"]}]},{"cell_type":"markdown","metadata":{"id":"h5phnoDzWj17"},"source":["<a id=\"GPU Settings\"><h2>Display Features</h2></a>"]},{"cell_type":"code","metadata":{"id":"aePYFbaoWj17","scrolled":false,"executionInfo":{"status":"ok","timestamp":1631221331760,"user_tz":-300,"elapsed":28,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}}},"source":["if DISPLAY_FEATURES: \n","    unified_df = training_data.copy()\n","    X_cols = unified_df.columns[:-1]\n","    y_cols = unified_df.columns[-1]\n","\n","\n","\n","    axarr = [[]]*len(X_cols)\n","    columns = 4\n","    rows = int( np.ceil( len(X_cols) / columns ) )\n","    f, fig = plt.subplots( figsize=(columns*2.5, rows*2) )\n","\n","    f.suptitle('Data Distributions by Feature and Label', size=16)\n","\n","    for i, col in enumerate(X_cols[:]):\n","        axarr[i] = plt.subplot2grid( (int(rows), int(columns)), (int(i//columns), int(i%columns)) )\n","\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 0, col ] , label=['Normal'], color=('#009933'), alpha=0.5,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 1, col ] , label=['Real Bot'], color=['#FF0000'], alpha=0.5,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","        axarr[i].set_xlabel(col, size=12)\n","    #     axarr[i].set_ylim([0,1])\n","        axarr[i].tick_params(axis='both', labelsize=10)\n","        if i == 0: \n","            legend = axarr[i].legend()\n","            legend.get_frame().set_facecolor('white')\n","        if i%4 != 0 : \n","            axarr[i].tick_params(axis='y', left=True, labelleft=True)\n","        else:\n","            axarr[i].set_ylabel('Fraction',size=12)\n","\n","    plt.tight_layout(rect=[0,0,1,0.95]) # xmin, ymin, xmax, ymax\n","    # plt.savefig('plots/Engineered_Data_Distributions.png')\n","\n","    plt.show()\n","    \n","# else: \n","#     print('Pair Plotting..')\n","# #     sns.pairplot(training_data, hue=\"Label\")\n","    \n","#     sns.pairplot(training_data, vars=['Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n","#        'Total Length of Fwd Packet', 'Total Length of Bwd Packet'], hue=\"Label\")\n","    \n","#     sns.pairplot(penguins, hue=\"species\", markers=[\"o\", \"s\", \"D\"])"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pD-Hq093Wj18"},"source":["<a id=\"GPU Settings\"><h2>Select Botnet</h2></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMdckAGdWj19","scrolled":true,"executionInfo":{"status":"ok","timestamp":1631221331761,"user_tz":-300,"elapsed":26,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"90f302c8-ca15-42f1-fe36-60e681a54713"},"source":["bots = training_data.loc[ training_data['Label']==0 ].copy()\n","normal = training_data.loc[ training_data['Label']==1 ].copy()\n","\n","print('Normal before chunk: ' + str(normal.shape))    \n","print('Real Bots before chunk: ' + str(bots.shape)) \n","\n","if take_chunk:\n","    bots = bots[0:512]\n","    \n","print('Normal: ' + str(normal.shape))    \n","print('Real Bots: ' + str(bots.shape)) "],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Normal before chunk: (246929, 61)\n","Real Bots before chunk: (1748, 61)\n","Normal: (246929, 61)\n","Real Bots: (1748, 61)\n"]}]},{"cell_type":"code","metadata":{"id":"WEv9Tz5AWj1-","executionInfo":{"status":"ok","timestamp":1631221332379,"user_tz":-300,"elapsed":634,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}}},"source":["Train = training_data.copy()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TrvNDY3Wj1-","scrolled":false,"executionInfo":{"status":"ok","timestamp":1631221332381,"user_tz":-300,"elapsed":34,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"7bd46daf-1287-49ed-ddae-e0a56c17a307"},"source":["bots_count =  pd.DataFrame( [ [np.sum(bots['Label']==i)] for i in np.unique(bots['Label']) ], columns=['count'], index=np.unique(bots['Label']) )\n","\n","label_cols = [ i for i in bots.columns if 'Label' in i ]\n","data_cols = [ i for i in bots.columns if i not in label_cols ]\n","\n","train_no_label = bots[ data_cols ].reset_index(drop=True)\n","\n","print(bots_count['count'])"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0    1748\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","metadata":{"id":"uKyFTGYfWj1_","executionInfo":{"status":"ok","timestamp":1631221332382,"user_tz":-300,"elapsed":19,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}}},"source":["train_data = bots"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_5UjRLxWj2B"},"source":["<a id=\"Classification\"><h1>Classification</h1></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"hPMsTK_pWj2B","scrolled":false,"executionInfo":{"status":"ok","timestamp":1631221333988,"user_tz":-300,"elapsed":1623,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"4855eba5-cc1a-44bf-8067-34ed7fbe089b"},"source":["%%time \n","# if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","if USE_KMEANS_FOR_CLASSIFICATION:\n","    algorithms = [ \n","    #     [ 'KMeans', cluster.KMeans, (), {'random_state':0} ],\n","        [ 'KMeans', cluster.KMeans, (), {'n_clusters':1, 'random_state':0} ],\n","    #     [ 'KMeans 3', cluster.KMeans, (), {'n_clusters':3, 'random_state':0} ],\n","    #     [ 'Agglomerative', cluster.AgglomerativeClustering, (), {} ],\n","    #     [ 'Agglomerative', cluster.AgglomerativeClustering, (), {'linkage': 'ward', 'n_clusters': 3} ],\n","    #     [ 'Agg. Ave 3', cluster.AgglomerativeClustering, (), {'linkage': 'average', 'n_clusters': 3} ],\n","    #     [ 'Agg. Complete 3', cluster.AgglomerativeClustering, (), {'linkage': 'complete', 'n_clusters': 3} ],\n","    #     [ 'DBSCAN', cluster.DBSCAN, (), {'eps':0.025} ],\n","    #     [ 'HDBSCAN', hdbscan.HDBSCAN, (), {} ],\n","    #     [ 'HDBSCAN', hdbscan.HDBSCAN, (), {'min_cluster_size':10, 'min_samples':1, } ],\n","    #     [ 'HDBSCAN 2 10', hdbscan.HDBSCAN, (), {'min_cluster_size':2, 'min_samples':10, } ],\n","    #     [ 'HDBSCAN 10 10 ', hdbscan.HDBSCAN, (), {'min_cluster_size':10, 'min_samples':10, } ],\n","    ]\n","\n","    rows = len(algorithms)\n","    columns = 1\n","    fig, ax = plt.subplots(3, 2, figsize=(3, 2),\n","                            constrained_layout=True)\n","\n","    for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","        labels = algorithm(*args, **kwds).fit_predict(train_no_label)\n","        print(len(labels))\n","        colors = np.clip(labels,-1,9)\n","        colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","        plt.subplot(rows,columns,i*columns+1)\n","        plt.scatter(train_no_label[data_cols[0]], train_no_label[data_cols[1]], c=colors)\n","        plt.xlabel(data_cols[0]), plt.ylabel(data_cols[1])\n","        plt.title(name)\n","            \n","\n","#     else:\n","#         labels = train_bots_only['Label'].values.tolist() \n","#         sns.set(style=\"ticks\", color_codes=True) # Remove background and grid\n","\n","#     #     g = sns.scatterplot(data_cols[0],data_cols[1], data=train, hue=labels)\n","\n","#     #     plt.show() \n","\n","\n","#         plt.figure()\n","#         ax = sns.countplot(y=\"Label\", data=train_bots_only) # for Seaborn version 0.7 and more\n","#         for p in ax.patches:\n","#             ax.text(p.get_y() + p.get_width() + 2700 , p.get_y()+p.get_height()-0.1, p.get_width(), ha=\"center\") \n","\n","#         ax.set_ylabel('Botnets')\n","\n","#         plt.savefig('Botnet-Trainset.pdf', dpi=600)\n","#         plt.show()\n","\n","\n","\n","\n","#         plt.figure(figsize=(6, 6))\n","#         ax = sns.countplot(y=\"Label\", data=test_bots_only) # for Seaborn version 0.7 and more\n","#         for p in ax.patches:\n","#             ax.text(p.get_y() + p.get_width() + 6000 , p.get_y()+p.get_height()-0.1, p.get_width(), ha=\"center\") \n","\n","#         ax.set_ylabel('Botnets')\n","\n","#         plt.savefig('Botnet-Testset.pdf', dpi=600)\n","#         plt.show()\n","\n","#     #     g = sns.catplot(x=\"class\", hue=\"who\", col=\"survived\", data=titanic, kind=\"count\", height=4, aspect=.7);\n","\n","\n","#     #     sns.pairplot(data=train, vars=[data_cols[0], data_cols[1]], hue='Label')\n","\n","\n","#     # plt.grid(False)\n","#     # plt.show()\n","#     print(train_no_label.describe())\n","    \n","    botnet_w_classes = train_no_label.copy()\n","    botnet_w_classes['Label'] = labels\n","\n","#     print(botnet_w_classes.describe())\n","    train_data = botnet_w_classes\n","    \n","# else:\n","#     train_data = train_no_label\n"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["1748\n","CPU times: user 257 ms, sys: 113 ms, total: 370 ms\n","Wall time: 262 ms\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 216x144 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmB4aCmMWj2D","scrolled":true,"executionInfo":{"status":"ok","timestamp":1631221333993,"user_tz":-300,"elapsed":54,"user":{"displayName":"Rizwan Hamid Randhawa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7k4GbU6Ynzl8VQrUNfXoiVGm4h7Zv4DOqW-TLA4A=s64","userId":"15615777248917371178"}},"outputId":"b2339d21-e1dc-4183-877f-2f2fcb499e6a"},"source":["train_data['Label']"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       0\n","1       0\n","2       0\n","3       0\n","4       0\n","       ..\n","1743    0\n","1744    0\n","1745    0\n","1746    0\n","1747    0\n","Name: Label, Length: 1748, dtype: int32"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"q168UjfTWj2E"},"source":["<a id=\"GPU Settings\"><h2>GAN Training</h2></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZBsZ9y_Wj2E","scrolled":false,"outputId":"ca12e490-14f0-4161-d687-f0486a7a1a4f"},"source":["# import header\n","# import importlib\n","# importlib.reload(header) # For reloading after making changes\n","# from header import *\n","\n","\n","gpu_device = '/device:GPU:1'\n","physical_devices = tf.config.list_physical_devices('GPU') \n","for gpu_instance in physical_devices: \n","    tf.config.experimental.set_memory_growth(gpu_instance, True)\n","\n","#----------------------------------\n","# Set neurons and batch size\n","#----------------------------------\n","base_n_count = 32\n","batch_size =  32\n","#----------------------------------\n","\n","\n","result = train_data\n","\n","remaining = train_data.shape[0] % batch_size\n","\n","if remaining > 0:\n","    if remaining < train_data.shape[0]:\n","        additional = batch_size - remaining\n","        _additional = train_data.loc[train_data.shape[0]-additional:train_data.shape[0],: ]  \n","        \n","        frames = [train_data, _additional]\n","        result = pd.concat(frames).reset_index(drop=True)\n","\n","print('Result: ' + str(result.shape))\n","# ---------------------------------\n","nb_steps = required_epochs * result.shape[0] // batch_size\n","\n","log_interval = result.shape[0] // batch_size # We are setting this as an epoch. This depends on data size.\n","\n","print(\"log_interval : \" + str(log_interval))\n","\n","# nb_steps = TRAINING_ITERATIONS  # 50000 # Add one for logging of the last interval\n","print(\"Total Batch Iterations: \" + str(nb_steps))\n","rand_noise_dim = 100 \n","\n","\n","k_d = 1  # number of critic network updates per adversarial training step\n","k_g = 1  # number of generator network updates per adversarial training step\n","\n","critic_pre_train_steps = 100# 100  # number of steps to pre-train the critic before starting adversarial training\n","\n","generator_model_path, discriminator_model_path, loss_pickle_path = None, None, None\n","\n","show = True \n","train = result#.copy().reset_index(drop=True) # botnet only with labels from classification\n","\n","\n","\n","label_cols = [ i for i in train.columns if 'Label' in i ]\n","\n","data_cols = [ i for i in train.columns if i not in label_cols ]\n","\n","print(data_cols)\n","\n","train_no_label = train[ data_cols ]\n","\n","train_no_label = round(train_no_label, 4)\n","\n","# if SAVE_ONLY_BOT_DATA:\n","#     train_no_label.to_csv(str(DATA_SET_PATH) + 'ONLY_BOTNET_DATA_(Preprocessed).csv')\n","#     print('File: ' + 'ONLY_BOTNET_DATA_(Preprocessed).csv saved to directory')   \n","\n","\n","\n","test_size = train.shape[0] \n","learning_rate = 5e-4\n","\n","for X in range(1):\n","\n","    TODAY = DATA_SET + '_' + str(datetime.datetime.now()) \n","\n","    print(TODAY)\n","\n","    Test = testing_data.copy()\n","\n","    arguments = [rand_noise_dim, nb_steps, batch_size, \n","                k_d, k_g, critic_pre_train_steps, log_interval, learning_rate, base_n_count,\n","                CACHE_PATH, FIGS_PATH, show, test_size, gpu_device, EVALUATION_PARAMETER, TODAY ]\n","\n","    if GAN_type == 'GAN':\n","        best_losses = adversarial_training_GAN(arguments, train_no_label, data_cols) # GAN    \n","    elif GAN_type == 'CGAN':    \n","        best_losses = adversarial_training_CGAN(arguments, train, data_cols=data_cols, label_cols=label_cols ) # CGAN      \n","    elif GAN_type == 'WGAN':\n","        best_losses = adversarial_training_WGAN(arguments, train_no_label, data_cols) # WGAN    \n","    elif GAN_type == 'WCGAN':    \n","        best_losses = adversarial_training_WCGAN(arguments, train, data_cols=data_cols, label_cols=label_cols ) # WCGAN      \n","        \n","        \n","    # if GAN_type == 'WGAN':\n","    #     best_losses = train_WGAN(arguments, train_no_label, data_cols)\n","        \n","    # elif GAN_type == 'GAN':\n","    #     best_losses = train_GAN(arguments, train_no_label, data_cols)\n","\n","\n","    elif GAN_type == 'EVAGAN':   \n","\n","        best_losses = train_EVAGAN(arguments, train, Train, Test, data_cols)\n","\n","    elif GAN_type == 'EVAGAN_CV':   \n","\n","        best_losses = train_EVAGAN_CV(arguments, train, Train, Test, data_cols)\n","        \n","        \n","        \n","    elif GAN_type == 'ACGAN_CC':   \n","\n","        best_losses = train_ACGAN_CC(arguments, train, Train, Test, data_cols)\n","        \n","    elif GAN_type == 'ACGAN_CV':   \n","\n","        best_losses = train_ACGAN_CV(arguments, train, Train, Test, data_cols)\n","        \n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Result: (1760, 61)\n","log_interval : 55\n","Total Batch Iterations: 8250\n","['Flow Duration', 'Total Fwd Packet', 'Total Bwd packets', 'Total Length of Fwd Packet', 'Total Length of Bwd Packet', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Fwd Segment Size Avg', 'Bwd Segment Size Avg', 'Bwd Bytes/Bulk Avg', 'Bwd Packet/Bulk Avg', 'Bwd Bulk Rate Avg', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Bytes', 'FWD Init Win Bytes', 'Bwd Init Win Bytes', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n","ISCX-2014_2021-09-09 21:02:13.474311\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 14, 14, 16)        160       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 14, 14, 16)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 14, 14, 16)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 7, 7, 32)          4640      \n","_________________________________________________________________\n","zero_padding2d (ZeroPadding2 (None, 8, 8, 32)          0         \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 32)          0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 8, 8, 32)          0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 8, 8, 32)          128       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 4, 4, 64)          18496     \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 4, 4, 64)          256       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2048)              0         \n","=================================================================\n","Total params: 97,536\n","Trainable params: 97,344\n","Non-trainable params: 192\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 6272)              633472    \n","_________________________________________________________________\n","reshape (Reshape)            (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n","_________________________________________________________________\n","activation (Activation)      (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 28, 28, 64)        73792     \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 28, 28, 1)         577       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 28, 28, 1)         0         \n","=================================================================\n","Total params: 856,705\n","Trainable params: 856,065\n","Non-trainable params: 640\n","_________________________________________________________________\n","label.shape: (None, 1)\n","Directory 'ISCX-2014_2021-09-09 21:02:13.474311' created\n","Directory 'ISCX-2014_2021-09-09 21:02:13.474311' created\n","EVAGAN_CV 32 32\n","======================================================\n","Batch Size Selected -------->>>>>>> 32\n","======================================================\n","x_Normal.shape: (4719, 28, 28)\n","x_Bots.shape: (414, 28, 28)\n","Starting GAN Training..\n","log_iteration: 1/150\n","Average time per log_iteration: 6.501576900482178\n","Time left = 16.2 minutes\n","Total Time Taken: 0.1 minutes\n","log_iteration: 2/150\n","Average time per log_iteration: 7.546742796897888\n","Time left = 18.6 minutes\n","Total Time Taken: 0.3 minutes\n","log_iteration: 3/150\n","Average time per log_iteration: 7.956652243932088\n","Time left = 19.2 minutes\n","Total Time Taken: 0.4 minutes\n","log_iteration: 4/150\n","Average time per log_iteration: 8.107752442359924\n","Time left = 19.8 minutes\n","Total Time Taken: 0.5 minutes\n","log_iteration: 5/150\n","Average time per log_iteration: 8.19932689666748\n","Time left = 19.8 minutes\n","Total Time Taken: 0.7 minutes\n","log_iteration: 6/150\n","Average time per log_iteration: 8.297097206115723\n","Time left = 19.8 minutes\n","Total Time Taken: 0.8 minutes\n","log_iteration: 7/150\n","Average time per log_iteration: 8.397673198154994\n","Time left = 19.8 minutes\n","Total Time Taken: 1.0 minutes\n","log_iteration: 8/150\n","Average time per log_iteration: 8.452717125415802\n","Time left = 19.8 minutes\n","Total Time Taken: 1.1 minutes\n","log_iteration: 9/150\n","Average time per log_iteration: 8.466972510019938\n","Time left = 19.8 minutes\n","Total Time Taken: 1.3 minutes\n","log_iteration: 10/150\n","Average time per log_iteration: 8.513896799087524\n","Time left = 19.8 minutes\n","Total Time Taken: 1.4 minutes\n","log_iteration: 11/150\n","Average time per log_iteration: 8.537180770527232\n","Time left = 19.8 minutes\n","Total Time Taken: 1.6 minutes\n","log_iteration: 12/150\n","Average time per log_iteration: 8.566668649514517\n","Time left = 19.8 minutes\n","Total Time Taken: 1.7 minutes\n"]}]},{"cell_type":"code","metadata":{"id":"unnBdzmKWj2I"},"source":["# %cd '/home/riz/Insync/rhr407@gmail.com/Google_Drive/PhD/Development/code/Current/Paper_2(v7)/figs/full/GAN/'\n","# !ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6FPvn-dVWj2K"},"source":["<a id=\"Columns\"><h1>Columns</h1></a>"]},{"cell_type":"code","metadata":{"id":"PiAGhsixWj2K","scrolled":false},"source":["X_cols = training_data.columns[:-1]\n","y_cols = training_data.columns[-1]\n","\n","print('X_cols: ' + str(X_cols))\n","print('y_cols: ' + str(y_cols))\n","\n","X = training_data[X_cols].values\n","Y = training_data['Label'].values\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6zbrUcwWj2L"},"source":["<a id=\"Run all Classifiers\"><h1>Split Datasets for Testing)</h1></a>"]},{"cell_type":"code","metadata":{"id":"_fp_-nkyWj2L"},"source":["if USE_ONLY_TRAIN_SET:\n","\n","    X = training_data[X_cols].values\n","    Y = training_data['Label'].values\n","\n","    # split data into train and test sets\n","    seed = 1\n","    test_size = 0.3\n","    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=11)\n","\n","    split_70_30 = True\n","\n","    print('Using Train set 70:30 split >>>>>>>')\n","\n","else:\n","\n","    X_train = training_data[X_cols].values\n","    y_train = training_data[y_cols].values\n","\n","    X_test = testing_data[X_cols].values\n","    y_test = testing_data[y_cols].values\n","\n","    print('Using Test Set for testing >>>>>>>') \n","\n","    split_70_30 = False\n","    \n","TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","TRAIN_TRAFFIC['Label'] = y_train\n","\n","BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","print('bot samples: ' + str(BOT_COUNTS))  \n","print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS =================================================================================================\n","REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","# REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]\n","\n","print(REAL_BOTS.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-4VAKaHWj2N"},"source":["<a id=\"Case7: Select Test Set\"><h2>Weights for Testing of each Classifier</h2></a>"]},{"cell_type":"code","metadata":{"id":"jZEEHEqMWj2N"},"source":["XGB_ACC_WEIGHT = best_losses[0]\n","XGB_RCL_WEIGHT = best_losses[1]\n","\n","DT_ACC_WEIGHT = best_losses[2]\n","DT_RCL_WEIGHT = best_losses[3]\n","\n","NB_ACC_WEIGHT = best_losses[4]\n","NB_RCL_WEIGHT = best_losses[5]\n","\n","RF_ACC_WEIGHT = best_losses[6]\n","RF_RCL_WEIGHT = best_losses[7]\n","\n","LR_ACC_WEIGHT = best_losses[8]\n","LR_RCL_WEIGHT = best_losses[9]\n","\n","KNN_ACC_WEIGHT = best_losses[10]\n","KNN_RCL_WEIGHT = best_losses[11]\n","\n","print(best_losses) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hy_LjMGXWj2O"},"source":["import pandas as pd\n","\n","dict = {'Best_Losses': best_losses}   \n","          \n","df = pd.DataFrame(dict) \n","# saving the dataframe  \n","# =============================================================================================    \n","df.to_csv(str(DATA_SET_PATH) + 'best_losses.csv')\n","print('File: ' + str(DATA_SET_PATH) + 'best_losses.csv saved to directory')  \n","# =============================================================================================    \n","print('Losses file saved')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rba8eHcIWj2P"},"source":["# if DATA_SET=='ISCX-2014':\n","#     if GAN_type=='GAN':\n","#         best_losses = [92, 15, 0, 99, 44, 44, 51, 107, 116, 116, 51, 51]\n","#     elif GAN_type=='CGAN':\n","#         best_losses = [100, 100, 121, 20, 102, 102, 100, 100,77, 77, 44, 44]\n","        \n","# elif DATA_SET=='CIC-2017':\n","#     if GAN_type=='GAN':\n","#         best_losses = [118, 118, 118, 118, 103, 103, 134, 134, 110, 110, 120, 127]\n","#     elif GAN_type=='CGAN':\n","#         best_losses = [69, 40, 139, 115, 80, 80, 80, 80, 0, 0, 40, 40]\n","\n","# elif DATA_SET=='CIC-2018':\n","#     if GAN_type=='GAN':\n","#         best_losses = [62, 62, 58, 58, 67, 67, 27, 27, 68, 68, 68, 68]\n","#     elif GAN_type=='CGAN':\n","#         best_losses = [114, 138, 93, 93, 0, 0, 14, 14, 121, 121, 121, 121]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9rAUzDNAWj2P"},"source":["<a id=\"Case7: Select Test Set\"><h1>KDE</h1></a>"]},{"cell_type":"code","metadata":{"id":"tGu3Y4bfWj2Q","scrolled":false},"source":["\n","import header\n","import importlib\n","importlib.reload(header) # For reloading after making changes\n","from header import *\n","\n","real_bots_df = bots[X_cols].copy()\n","real_bots_df['Type'] = 'Real Bots'\n","\n","print(real_bots_df.shape)\n","\n","# fig, ax = plt.subplots(6, 1, figsize=(1, 5), constrained_layout=True)\n","for i in range(0, len(best_losses), 2):\n","    \n","    gan_bots_acc = generate_gan_data(real_bots_df, labels = labels, weight_or_epoch_number = best_losses[i], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","    gan_bots_rcl = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i+1], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","    \n","    print(gan_bots_acc.shape)\n","    print(gan_bots_rcl.shape)\n","\n","#     gan_bots_acc = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","#     gan_bots_rcl = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = 32, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","    \n","    gan_bots_acc['Type'] = 'GAN Bots (C2ST)'\n","    gan_bots_rcl['Type'] = 'GAN Bots (BotShot)'\n","\n","\n","    data_frame = pd.concat([gan_bots_acc, gan_bots_rcl]).reset_index(drop=True).copy()\n","    data_frame_of_bots = pd.concat([real_bots_df, data_frame]).reset_index(drop=True).copy()\n","    \n","    # =============================================================================================    \n","    data_frame_of_bots.to_csv(str(DATA_SET_PATH) + GAN_type + '_data_frame_of_bots_' + str(i) + '.csv')\n","    print('File: ' + str(DATA_SET_PATH) + GAN_type + '_data_frame_of_bots_' + str(i) + '.csv saved to directory')  \n","    # =============================================================================================    \n","\n","    print(gan_bots_acc.shape)\n","    print(gan_bots_rcl.shape)\n","#     fig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\n","\n","\n","#     for j in range(len(data_cols)):\n","#         print(j)\n","#     sns.kdeplot(data = data_frame_of_bots, x = data_cols[44], y = data_cols[45],  bw_adjust=7, fill = False, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","#     sns.displot(data=data_frame_of_bots, x=data_cols[44], kind=\"kde\", hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'], bw_adjust=7)\n","    \n","\n","    fig, ax = pyplot.subplots(figsize=(5, 3.5))\n","\n","#     plt.xlim(-2, 2)\n","#     plt.ylim(-2, 1) \n","\n","    if DATA_SET=='CIC-2017':\n","        X = 'BwdPacketLengthStd'\n","    else:\n","        X = 'Bwd Pkt Len Std'\n","\n","    \n","    for j in range(len(data_cols)):\n","        print(j)\n","        g = sns.kdeplot(data = data_frame_of_bots, x = data_cols[j], bw_adjust=6, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'],  fill=False, common_norm=False, alpha=.6)\n","        plt.xlim(-1, 3)\n","        plt.ylim(-1, 3)\n","        \n","        \n","        plt.show()\n","        plt.close()\n","#     g = sns.kdeplot(data = data_frame_of_bots, x = X, bw_adjust=6, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'],  fill=False, common_norm=False, alpha=.6)\n","\n","#     ax.legend(loc='upper left')\n","#     g.set_ylabels(\"survival probability\")\n","\n","    \n","#     g.set_ylabels(\"survival probability\")\n","\n","#     sns.scatterplot(data = data_frame_of_bots, x = data_cols[44], y = data_cols[45], hue = 'Type', alpha = 0.4,   style = \"Type\")\n","#     g.legend(fontsize = 15, bbox_to_anchor= (1.03, 1), title=\"Delivery Type\", title_fontsize = 18, shadow = True, facecolor = 'white')    \n","\n","    plt.savefig(GAN_type + '_' + str(i) + 'contour.eps', dpi=600)\n","    \n","\n","    plt.show()\n","    plt.close()\n","#         plt.legend(loc='lower left', bbox_to_anchor= (0.0, 1.01), ncol=3, borderaxespad=0, frameon=False)\n","#     sns.kdeplot(data = data_frame_of_bots, x = data_cols[49], y = data_cols[50],  bw_adjust=6, fill = False, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","#     plt.show()\n","#     plt.close()\n","\n","#     sns.kdeplot(data = data_frame_of_bots, x = data_cols[52], y = data_cols[53],  bw_adjust=6, fill = False, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","#     plt.show()\n","#     plt.close()\n","\n","#     sns.kdeplot(data = data_frame_of_bots, x = data_cols[58], y = data_cols[59],  bw_adjust=6, fill = False, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","#     plt.show()\n","#     plt.close()\n","\n","#         plt.tight_layout()\n","#         sns.jointplot(data=data_frame_of_bots, x=data_cols[5], y=data_cols[6], hue=\"Type\", kind=\"kde\")\n","#         sns.displot(data=data_frame_of_bots, x=data_cols[j], kde=True, hue = 'Type', hue_order= ['Real Bots', 'GAN Bots (C2ST)', 'GAN Bots (BotShot)'])\n","    \n","    #     plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)    \n","        \n","\n","    #     sns.displot(data = data_frame_of_bots, x = data_cols[5], kind = 'kde', hue=\"Type\")    \n","\n","\n","#     sns.scatterplot(data = data_frame_of_bots, x = data_cols[5], y = data_cols[6], hue = 'Type', alpha = 0.4,   style = \"Type\")\n","    \n","#     plt.legend(loc='lower left', bbox_to_anchor= (0.0, 1.01), ncol=3, borderaxespad=0, frameon=False)\n","#     plt.tight_layout()\n","#     sns.jointplot(data=data_frame_of_bots, x=data_cols[5], y=data_cols[6], hue=\"Type\", kind=\"kde\")\n","#     plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)    \n","#     plt.xlim(-.06, .06)\n","#     plt.ylim(-.05, .05)\n","\n","#     plt.show()\n","#     plt.close()    \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"njMS-4A2Wj2S"},"source":["# Data generated using accuracy weights\n","\n","\n","# real_bots_df = bots[X_cols].copy()\n","# real_bots_df['Type'] = 'Real Bots'\n","\n","# data_frame_of_bots = real_bots_df\n","\n","# classifiers = ['XGB', 'DT', 'NB', 'RF', 'LR', 'KNN']\n","\n","# for (j, i) in zip(classifiers, range(0, len(best_losses), 2)):\n","#     gan_bots_acc = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","#     gan_bots_acc['Type'] = j + '_GAN Bots(C2ST)'\n","    \n","# #     gan_bots_acc = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i+1], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","# #     gan_bots_acc['Type'] = j + '_GAN Bots(Acc)'\n","#     data_frame_of_bots = pd.concat([data_frame_of_bots, gan_bots_acc]).reset_index(drop=True).copy()\n","\n","\n","# sns.kdeplot(data = data_frame_of_bots, x = 'Total Length of Fwd Packet', y = 'Total Length of Bwd Packet',  bw_adjust=2, fill = False, hue = 'Type')\n","# plt.xlim(-.05, .09)\n","# plt.ylim(-.06, .07)\n","\n","\n","\n","# plt.show()\n","# plt.close(fig)\n","\n","\n","\n","\n","# # Data generated using recall weights\n","\n","\n","\n","# real_bots_df = bots[X_cols].copy()\n","# real_bots_df['Type'] = 'Real Bots'\n","\n","# data_frame_of_bots = real_bots_df\n","\n","# classifiers = ['XGB', 'DT', 'NB', 'RF', 'LR', 'KNN']\n","\n","# for (j, i) in zip(classifiers, range(0, len(best_losses), 2)):\n","#     gan_bots_acc = generate_gan_data(real_bots_df, labels, weight_or_epoch_number = best_losses[i], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = real_bots_df.shape[0])\n","#     gan_bots_acc['Type'] = j + '_GAN Bots(Botshot)'\n","#     data_frame_of_bots = pd.concat([data_frame_of_bots, gan_bots_acc]).reset_index(drop=True).copy()\n","\n","# print(gan_bots_acc.shape)\n","# print(gan_bots_rcl.shape)\n","\n","# sns.kdeplot(data = data_frame_of_bots, x = 'Total Length of Fwd Packet', y = 'Total Length of Bwd Packet',  bw_adjust=2, fill = False, hue = 'Type')\n","# plt.xlim(-.05, .09)\n","# plt.ylim(-.06, .07)\n","\n","# plt.show()\n","# plt.close(fig)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sqo5edIWj2T"},"source":["<a id=\"Case7: Select Test Set\"><h1>Blackbox Attack [C2ST]</h1></a>"]},{"cell_type":"code","metadata":{"id":"_ThFwtQrWj2T","scrolled":false},"source":["if C2ST_BLACK_BOX_TEST:\n","    for i in range(10): # 10-folds testing\n","        # split data into train and test sets\n","        seed = i\n","        test_size = 0.3\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","        split_70_30 = True\n","\n","        print('Using Train set 70:30 split >>>>>>>')\n","        print(len(X_train), len(X_test), len(y_train), len(y_test))\n","\n","#============================================== REAL BOTS =================================================================================================\n","\n","        TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","        TRAIN_TRAFFIC['Label'] = y_train\n","\n","        BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","        BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","        print('bot samples in TRAIN_TRAFFIC: ' + str(BOT_COUNTS))  \n","        print('benign samples in TRAIN_TRAFFIC: ' + str(BENIGN_COUNTS))\n","\n","\n","        TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS ===============================================================================================\n","        REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","        BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","#============================================== Oversample bots for data balancing =======================================================================        \n","        if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","            df = REAL_BOTS.copy()\n","            DATA_SIZE = BENIGN_SAMPLES\n","\n","            for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                df = pd.concat([df, REAL_BOTS])\n","\n","            REAL_BOTS = df.copy()\n","            print(REAL_BOTS.shape)\n","            REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","     #============================================== Generate Labels =========================================================================================        \n","\n","            algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","            rows = len(algorithms)\n","            columns = 1\n","            fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                    constrained_layout=True)\n","\n","            for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                colors = np.clip(labels,-1,9)\n","                colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                plt.subplot(rows,columns,i*columns+1)\n","                plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                plt.title(name)\n","#============================================== Testing =================================================================================================        \n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = XGB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running XGB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = DT_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running DT ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = NB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running NB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number =RF_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running RF ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = LR_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running LR ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=LogisticRegression(max_iter=1000) )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = KNN_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running KNN ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KZ0R8JzdWj2V"},"source":["<a id=\"Case7: Select Test Set\"><h1>Blackbox Attack [BOTSHOT]</h1></a>"]},{"cell_type":"code","metadata":{"id":"qNhWSR7GWj2W","scrolled":false},"source":["if BOTSHOT_BLACK_BOX_TEST:\n","    for i in range(10): # 10-folds testing\n","        # split data into train and test sets\n","        seed = i\n","        test_size = 0.3\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","        split_70_30 = True\n","\n","        print('Using Train set 70:30 split >>>>>>>')\n","        print(len(X_train), len(X_test), len(y_train), len(y_test))\n","\n","#============================================== REAL BOTS =================================================================================================\n","\n","        TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","        TRAIN_TRAFFIC['Label'] = y_train\n","\n","        BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","        BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","        print('bot samples in TRAIN_TRAFFIC: ' + str(BOT_COUNTS))  \n","        print('benign samples in TRAIN_TRAFFIC: ' + str(BENIGN_COUNTS))\n","\n","\n","        TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS ===============================================================================================\n","        REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","        BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","#============================================== Oversample bots for data balancing =======================================================================        \n","        if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","            df = REAL_BOTS.copy()\n","            DATA_SIZE = BENIGN_SAMPLES\n","\n","            for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                df = pd.concat([df, REAL_BOTS])\n","\n","            REAL_BOTS = df.copy()\n","            print(REAL_BOTS.shape)\n","            REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","     #============================================== Generate Labels =========================================================================================        \n","\n","            algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","            rows = len(algorithms)\n","            columns = 1\n","            fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                    constrained_layout=True)\n","\n","            for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                colors = np.clip(labels,-1,9)\n","                colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                plt.subplot(rows,columns,i*columns+1)\n","                plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                plt.title(name)\n","#============================================== Testing =================================================================================================        \n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = XGB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running XGB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = DT_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running DT ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = NB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running NB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number =RF_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running RF ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = LR_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running LR ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=LogisticRegression(max_iter=1000) )   \n","\n","\n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = KNN_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running KNN ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4P0ckpYgWj2Y"},"source":["<a id=\"Case3: Select Test Set\"><h1>Visually Test Overlapping</h1>"]},{"cell_type":"code","metadata":{"id":"ssRiN-1XWj2Y"},"source":["if VISUAL_TEST_OVERLAPPING:\n","\n","    axarr = [[]]*len(X_cols)\n","    columns = 4\n","    rows = int( np.ceil( len(X_cols) / columns ) )\n","    f, fig = plt.subplots( figsize=(columns*2.5, rows*2) )\n","\n","    f.suptitle('Data Distributions by Feature and Label', size=16)\n","\n","    for i, col in enumerate(X_cols[:]):\n","        axarr[i] = plt.subplot2grid( (int(rows), int(columns)), (int(i//columns), int(i%columns)) )\n","\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 0, col ] , label=['Normal'], color=('#009933'), alpha=0.6,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 1, col ] , label=['Real Bot'], color=['#FF0000'], alpha=0.5,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","        axarr[i].hist( unified_df.loc[ unified_df.Label == 2, col ] , label=['GAN Bot'], color=['#0000ff'], alpha=0.4,\n","                              bins=np.linspace( np.percentile(unified_df[col],0), np.percentile(unified_df[col],100),50 ),\n","                              density=True )\n","\n","\n","\n","\n","\n","        axarr[i].set_xlabel(col, size=12)\n","    #     axarr[i].set_ylim([0,1])\n","        axarr[i].tick_params(axis='both', labelsize=10)\n","        if i == 0: \n","            legend = axarr[i].legend()\n","            legend.get_frame().set_facecolor('white')\n","        if i%4 != 0 : \n","            axarr[i].tick_params(axis='y', left=True, labelleft=True)\n","        else:\n","            axarr[i].set_ylabel('Fraction',size=12)\n","\n","    plt.tight_layout(rect=[0,0,1,0.95]) # xmin, ymin, xmax, ymax\n","    # plt.savefig('plots/Engineered_Data_Distributions.png')\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUgIBYO6Wj2a"},"source":["import classifiers\n","import importlib\n","importlib.reload(classifiers) # For reloading after making changes\n","from classifiers import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeKihgCHWj2a"},"source":["<a id=\"Case7: Select Test Set\"><h1>GAN [DATA AUG: C2ST]</h1></a>"]},{"cell_type":"code","metadata":{"id":"k6NBYFOxWj2a"},"source":["GAN_aug_accu_list = []\n","GAN_aug_rcl_list = []\n","GAN_aug_prec_list = []\n","GAN_aug_f1_list = []\n","\n","del GAN_aug_accu_list \n","del GAN_aug_rcl_list \n","del GAN_aug_prec_list \n","del GAN_aug_f1_list\n","\n","GAN_aug_accu_list = []\n","GAN_aug_rcl_list = []\n","GAN_aug_prec_list = []\n","GAN_aug_f1_list = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"phHeLhx3Wj2b","scrolled":false},"source":["if ACCU_EVAL_TEST:  \n","    if USE_ONLY_TRAIN_SET:\n","\n","        for k in range(10): # 10-folds testing\n","            \n","            # split data into train and test sets\n","            seed = k\n","            test_size = 0.3\n","            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","            split_70_30 = True\n","\n","            print('Using Train set 70:30 split >>>>>>>')\n","    #============================================== Assign Values ==========================================================================================\n","            TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","            TRAIN_TRAFFIC['Label'] = y_train\n","\n","            BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","            BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","            print('bot samples: ' + str(BOT_COUNTS))  \n","            print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","            TRAIN_TRAFFIC.columns = training_data.columns\n","            \n","            REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","            BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","            \n","            if BALANCE_THE_DATASET:\n","                df = REAL_BOTS.copy()\n","\n","                for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                    df = pd.concat([df, REAL_BOTS]).copy()\n","                    \n","                df = pd.concat([df, REAL_BOTS[0: BENIGN_COUNTS%BOT_COUNTS]]).copy() # add the remaining bots\n","                    \n","                print(df.shape)\n","                \n","                df = df[0:df.shape[0] - 2 * (REAL_BOTS.shape[0])].copy() # We need to balance data so the labels will be generated of this size.We subtracted REAL_BOTS.shape[0] twice in order to balance bots with normal data.\n","                BIG_REAL_BOTS = df.copy()\n","\n","                print(df.shape)\n","    #============================================== Oversample bots for data balancing =======================================================================        \n","            if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","\n","                BIG_REAL_BOTS_WITHOUT_LABEL = BIG_REAL_BOTS[BIG_REAL_BOTS.columns[:-1]]      \n","         #============================================== Generate Labels =========================================================================================        \n","\n","                algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","                rows = len(algorithms)\n","                columns = 1\n","                fig, ax = plt.subplots(3, 2, figsize=(5, 3), constrained_layout=True)\n","                plt.xlim(0, 1)\n","\n","\n","                for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                    labels = algorithm(*args, **kwds).fit_predict(BIG_REAL_BOTS_WITHOUT_LABEL)\n","                    colors = np.clip(labels,-1,9)\n","                    colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                    plt.subplot(rows,columns,i*columns+1)\n","                    plt.scatter(BIG_REAL_BOTS_WITHOUT_LABEL[X_cols[0]], BIG_REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                    plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                    plt.title(name)\n","                    \n","    #============================================== Testing =================================================================================================        \n","            print(i)    \n","            \n","            GAN_BOTS_XGB_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = XGB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","            X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_XGB_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'XGB')\n","            print('Running XGB ...')     \n","            clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","            \n","            if USE_ALL_CLASSIFIERS :\n","                \n","                GAN_BOTS_DT_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = DT_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_DT_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'DT')\n","                print('Running DT ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","                GAN_BOTS_NB_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = NB_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_NB_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'NB')\n","                print('Running NB ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","                GAN_BOTS_RF_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = RF_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_RF_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'RF')\n","                print('Running RF ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","                GAN_BOTS_LR_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = LR_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_LR_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'LR')\n","                print('Running LR ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list,  clf=LogisticRegression(max_iter=1000) )   \n","\n","                GAN_BOTS_KNN_ACC_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = KNN_ACC_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_KNN_ACC_WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = 'KNN')\n","                print('Running KNN ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wf0cBJ0NWj2c"},"source":["<a id=\"Case7: Select Test Set\"><h1>GAN [Evaluation: ACCURACY with data generated on single classfier weight of Generator]</h1></a>"]},{"cell_type":"code","metadata":{"id":"CyicsWsOWj2c","scrolled":false},"source":["if SINGLE_WEIGHT_CLASSIFIER_TEST_C2ST:\n","\n","    GAN_aug_accu_list = []\n","    GAN_aug_rcl_list = []\n","    GAN_aug_prec_list = []\n","    GAN_aug_f1_list = []\n","\n","    del GAN_aug_accu_list \n","    del GAN_aug_rcl_list \n","    del GAN_aug_prec_list \n","    del GAN_aug_f1_list\n","\n","    GAN_aug_accu_list = []\n","    GAN_aug_rcl_list = []\n","    GAN_aug_prec_list = []\n","    GAN_aug_f1_list = []\n","\n","    if ACCU_EVAL_TEST:  \n","        if USE_ONLY_TRAIN_SET:\n","\n","            for k in range(10): # 10-folds testing\n","                # split data into train and test sets\n","                seed = k\n","                test_size = 0.3\n","                X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","                split_70_30 = True\n","\n","                print('Using Train set 70:30 split >>>>>>>')\n","        #============================================== Assign Values ==========================================================================================\n","                TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","                TRAIN_TRAFFIC['Label'] = y_train\n","\n","                BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","                BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","                print('bot samples: ' + str(BOT_COUNTS))  \n","                print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","                TRAIN_TRAFFIC.columns = training_data.columns\n","        #============================================== REAL BOTS ===============================================================================================\n","                REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","                BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","        #============================================== Oversample bots for data balancing =======================================================================        \n","                if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","\n","                    df = REAL_BOTS.copy()\n","                    DATA_SIZE = BENIGN_SAMPLES\n","\n","                    for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                        df = pd.concat([df, REAL_BOTS])\n","\n","                    REAL_BOTS = df.copy()\n","                    print(REAL_BOTS.shape)\n","                    REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","             #============================================== Generate Labels =========================================================================================        \n","\n","                    algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","                    rows = len(algorithms)\n","                    columns = 1\n","                    fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                            constrained_layout=True)\n","\n","                    for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                        labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                        colors = np.clip(labels,-1,9)\n","                        colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                        plt.subplot(rows,columns,i*columns+1)\n","                        plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                        plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                        plt.title(name)\n","        #============================================== Testing =================================================================================================        \n","\n","                classifiers = [XGBClassifier(), DecisionTreeClassifier(), GaussianNB(), RandomForestClassifier(n_estimators=100), LogisticRegression(max_iter=1000), KNeighborsClassifier(n_neighbors=5)]\n","\n","                for l in  range(0, len(best_losses), 2):\n","\n","                    GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = best_losses[l], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = REAL_BOTS.shape[0])\n","                    print(GAN_BOTS.shape)\n","                    #plot_kde(REAL_BOTS, GAN_BOTS, BENIGN_SAMPLES, with_class = True)    \n","                    X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS, training_data.columns)\n","                    print('Data generating using ' + str(i))\n","\n","                    for j in classifiers:\n","\n","                        print('Running ' + str(j) )    \n","                        clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=j )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dwb2HGoqWj2d"},"source":["<a id=\"Case7: Select Test Set\"><h1>GAN [Evaluation: RECALL with data generated on single classfier weight of Generator]</h1></a>"]},{"cell_type":"code","metadata":{"id":"pSMvBkqVWj2e","scrolled":false},"source":["if SINGLE_WEIGHT_CLASSIFIER_TEST_PROPOSED_METHODOLOGY:\n","\n","    RCL_GAN_aug_accu_list = []\n","    RCL_GAN_aug_rcl_list = []\n","    RCL_GAN_aug_prec_list = []\n","    RCL_GAN_aug_f1_list = []\n","\n","    del RCL_GAN_aug_accu_list \n","    del RCL_GAN_aug_rcl_list \n","    del RCL_GAN_aug_prec_list \n","    del RCL_GAN_aug_f1_list\n","\n","    RCL_GAN_aug_accu_list = []\n","    RCL_GAN_aug_rcl_list = []\n","    RCL_GAN_aug_prec_list = []\n","    RCL_GAN_aug_f1_list = []\n","\n","    if ACCU_EVAL_TEST:  \n","        if USE_ONLY_TRAIN_SET:\n","\n","            for k in range(10): # 10-folds testing\n","                # split data into train and test sets\n","                seed = k\n","                test_size = 0.3\n","                X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","                split_70_30 = True\n","\n","                print('Using Train set 70:30 split >>>>>>>')\n","        #============================================== Assign Values ==========================================================================================\n","                TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","                TRAIN_TRAFFIC['Label'] = y_train\n","\n","                BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","                BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","                print('bot samples: ' + str(BOT_COUNTS))  \n","                print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","                TRAIN_TRAFFIC.columns = training_data.columns\n","        #============================================== REAL BOTS ===============================================================================================\n","                REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","                BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","        #============================================== Oversample bots for data balancing =======================================================================        \n","                if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","\n","                    df = REAL_BOTS.copy()\n","                    DATA_SIZE = BENIGN_SAMPLES\n","\n","                    for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                        df = pd.concat([df, REAL_BOTS])\n","\n","                    REAL_BOTS = df.copy()\n","                    print(REAL_BOTS.shape)\n","                    REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","             #============================================== Generate Labels =========================================================================================        \n","\n","                    algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","                    rows = len(algorithms)\n","                    columns = 1\n","                    fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                            constrained_layout=True)\n","\n","                    for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                        labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                        colors = np.clip(labels,-1,9)\n","                        colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                        plt.subplot(rows,columns,i*columns+1)\n","                        plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                        plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                        plt.title(name)\n","        #============================================== Testing =================================================================================================        \n","\n","                classifiers = [XGBClassifier(), DecisionTreeClassifier(), GaussianNB(), RandomForestClassifier(n_estimators=100), LogisticRegression(max_iter=1000), KNeighborsClassifier(n_neighbors=5)]\n","\n","                for l in  range(1, len(best_losses), 2):\n","\n","                    GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = best_losses[l], data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = REAL_BOTS.shape[0] * 2)\n","                    print(GAN_BOTS.shape)\n","                    #plot_kde(REAL_BOTS, GAN_BOTS, BENIGN_SAMPLES, with_class = True)    \n","                    X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS, training_data.columns)\n","                    print('Data generating using ' + str(i))\n","\n","                    for j in classifiers:\n","\n","                        print('Running ' + str(j) )    \n","                        clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=j )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kG27_EGoWj2f"},"source":["<a id=\"Case7: Select Test Set\"><h1>GAN [Evaluation: BOTSHOT]</h1></a>"]},{"cell_type":"code","metadata":{"id":"VGRRjN_mWj2i","scrolled":false},"source":["RCL_GAN_aug_accu_list = []\n","RCL_GAN_aug_rcl_list = []\n","RCL_GAN_aug_prec_list = []\n","RCL_GAN_aug_f1_list = []\n","\n","del RCL_GAN_aug_accu_list \n","del RCL_GAN_aug_rcl_list \n","del RCL_GAN_aug_prec_list \n","del RCL_GAN_aug_f1_list\n","\n","RCL_GAN_aug_accu_list = []\n","RCL_GAN_aug_rcl_list = []\n","RCL_GAN_aug_prec_list = []\n","RCL_GAN_aug_f1_list = []\n","\n","\n","if RCL_EVAL_TEST:  \n","    if USE_ONLY_TRAIN_SET:\n","\n","        for k in range(10): # 10-folds testing\n","            \n","            # split data into train and test sets\n","            seed = k\n","            test_size = 0.3\n","            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","            split_70_30 = True\n","\n","            print('Using Train set 70:30 split >>>>>>>')\n","    #============================================== Assign Values ==========================================================================================\n","            TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","            TRAIN_TRAFFIC['Label'] = y_train\n","\n","            BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","            BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","            print('bot samples: ' + str(BOT_COUNTS))  \n","            print('benign samples: ' + str(BENIGN_COUNTS))\n","\n","            TRAIN_TRAFFIC.columns = training_data.columns\n","            \n","            REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","            BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","            \n","            if BALANCE_THE_DATASET:\n","                df = REAL_BOTS.copy()\n","\n","                for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                    df = pd.concat([df, REAL_BOTS]).copy()\n","                    \n","                df = pd.concat([df, REAL_BOTS[0: BENIGN_COUNTS%BOT_COUNTS]]).copy() # add the remaining bots\n","                    \n","                print(df.shape)\n","                \n","                df = df[0:df.shape[0] - 2 * (REAL_BOTS.shape[0])].copy() # We need to balance data so the labels will be generated of this size.We subtracted REAL_BOTS.shape[0] twice in order to balance bots with normal data.\n","                BIG_REAL_BOTS = df.copy()\n","\n","                print(df.shape)\n","    #============================================== Oversample bots for data balancing =======================================================================        \n","            if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","\n","                BIG_REAL_BOTS_WITHOUT_LABEL = BIG_REAL_BOTS[BIG_REAL_BOTS.columns[:-1]]      \n","         #============================================== Generate Labels =========================================================================================        \n","\n","                algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","                rows = len(algorithms)\n","                columns = 1\n","                fig, ax = plt.subplots(3, 2, figsize=(5, 3), constrained_layout=True)\n","                plt.xlim(0, 1)\n","\n","\n","                for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                    labels = algorithm(*args, **kwds).fit_predict(BIG_REAL_BOTS_WITHOUT_LABEL)\n","                    colors = np.clip(labels,-1,9)\n","                    colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                    plt.subplot(rows,columns,i*columns+1)\n","                    plt.scatter(BIG_REAL_BOTS_WITHOUT_LABEL[X_cols[0]], BIG_REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                    plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                    plt.title(name)\n","                    \n","    #============================================== Testing =================================================================================================        \n","            print(i)    \n","            \n","            GAN_BOTS_XGB_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = XGB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","            X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_XGB_RCL_WEIGHT, training_data.columns)\n","            print('Running XGB ...')     \n","            clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=XGBClassifier() )   \n","                \n","            if USE_ALL_CLASSIFIERS :\n","\n","                GAN_BOTS_DT_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = DT_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_DT_RCL_WEIGHT, training_data.columns)\n","                print('Running DT ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","                GAN_BOTS_NB_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = NB_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_NB_RCL_WEIGHT, training_data.columns)\n","                print('Running NB ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","                GAN_BOTS_RF_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = RF_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_RF_RCL_WEIGHT, training_data.columns)\n","                print('Running RF ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","                GAN_BOTS_LR_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = LR_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_LR_RCL_WEIGHT, training_data.columns)\n","                print('Running LR ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list,  clf=LogisticRegression(max_iter=1000) )   \n","\n","                GAN_BOTS_KNN_RCL_WEIGHT = generate_gan_data(BIG_REAL_BOTS, labels, weight_or_epoch_number = KNN_RCL_WEIGHT, data_dim = len(X_cols), FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BIG_REAL_BOTS.shape[0])\n","                X_TRAIN, y_TRAIN = augment_bots(X_train, y_train, GAN_BOTS_KNN_RCL_WEIGHT, training_data.columns)\n","                print('Running KNN ...')     \n","                clsfr_train_test(X_TRAIN, y_TRAIN, X_test, y_test, accu_list = RCL_GAN_aug_accu_list, rcl_list = RCL_GAN_aug_rcl_list, prec_list = RCL_GAN_aug_prec_list , f1_list = RCL_GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-J4LBGRWj2j"},"source":["<a id=\"Case7: Select Test Set\"><h1>Blackbox Attack AFTER GAN TRAINING[C2ST]</h1></a>"]},{"cell_type":"code","metadata":{"id":"-G_Q5ZcjWj2j"},"source":["if C2ST_BLACK_BOX_TEST_AFTER_GAN_TRAINING:\n","    for i in range(10): # 10-folds testing\n","        # split data into train and test sets\n","        seed = i\n","        test_size = 0.3\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","        split_70_30 = True\n","\n","        print('Using Train set 70:30 split >>>>>>>')\n","        print(len(X_train), len(X_test), len(y_train), len(y_test))\n","\n","#============================================== REAL BOTS =================================================================================================\n","\n","        TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","        TRAIN_TRAFFIC['Label'] = y_train\n","\n","        BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","        BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","        print('bot samples in TRAIN_TRAFFIC: ' + str(BOT_COUNTS))  \n","        print('benign samples in TRAIN_TRAFFIC: ' + str(BENIGN_COUNTS))\n","\n","\n","        TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS ===============================================================================================\n","        REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","        BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","#============================================== Oversample bots for data balancing =======================================================================        \n","        if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","            df = REAL_BOTS.copy()\n","            DATA_SIZE = BENIGN_SAMPLES\n","\n","            for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                df = pd.concat([df, REAL_BOTS])\n","\n","            REAL_BOTS = df.copy()\n","            print(REAL_BOTS.shape)\n","            REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","     #============================================== Generate Labels =========================================================================================        \n","\n","            algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","            rows = len(algorithms)\n","            columns = 1\n","            fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                    constrained_layout=True)\n","\n","            for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                colors = np.clip(labels,-1,9)\n","                colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                plt.subplot(rows,columns,i*columns+1)\n","                plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                plt.title(name)\n","#============================================== Testing =================================================================================================        \n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = XGB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running XGB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","\n","        if USE_ALL_CLASSIFIERS :\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = DT_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running DT ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = NB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running NB ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number =RF_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running RF ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = LR_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running LR ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=LogisticRegression(max_iter=1000) )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = KNN_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running KNN ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dmSnTHqvWj2l"},"source":["<a id=\"Case7: Select Test Set\"><h1>Blackbox Attack AFTER GAN TRAINING[BOTSHOT]</h1></a>"]},{"cell_type":"code","metadata":{"id":"l3wrJMOWWj2m"},"source":["if BOTSHOT_BLACK_BOX_TEST_AFTER_GAN_TRAINING:\n","    for i in range(10): # 10-folds testing\n","        # split data into train and test sets\n","        seed = i\n","        test_size = 0.3\n","        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","\n","        split_70_30 = True\n","\n","        print('Using Train set 70:30 split >>>>>>>')\n","        print(len(X_train), len(X_test), len(y_train), len(y_test))\n","\n","#============================================== REAL BOTS =================================================================================================\n","\n","        TRAIN_TRAFFIC = pd.DataFrame(X_train) \n","        TRAIN_TRAFFIC['Label'] = y_train\n","\n","        BOT_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[1]\n","        BENIGN_COUNTS = TRAIN_TRAFFIC['Label'].value_counts()[0]   \n","\n","        print('bot samples in TRAIN_TRAFFIC: ' + str(BOT_COUNTS))  \n","        print('benign samples in TRAIN_TRAFFIC: ' + str(BENIGN_COUNTS))\n","\n","\n","        TRAIN_TRAFFIC.columns = training_data.columns\n","#============================================== REAL BOTS ===============================================================================================\n","        REAL_BOTS = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==1 ].copy().reset_index(drop=True) # Real Botnets\n","        BENIGN_SAMPLES = TRAIN_TRAFFIC.loc[ TRAIN_TRAFFIC['Label']==0 ].copy().reset_index(drop=True) # Benign Samples\n","#============================================== Oversample bots for data balancing =======================================================================        \n","        if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","            df = REAL_BOTS.copy()\n","            DATA_SIZE = BENIGN_SAMPLES\n","\n","            for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","                df = pd.concat([df, REAL_BOTS])\n","\n","            REAL_BOTS = df.copy()\n","            print(REAL_BOTS.shape)\n","            REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n","     #============================================== Generate Labels =========================================================================================        \n","\n","            algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","            rows = len(algorithms)\n","            columns = 1\n","            fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                    constrained_layout=True)\n","\n","            for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","                labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","                colors = np.clip(labels,-1,9)\n","                colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","                plt.subplot(rows,columns,i*columns+1)\n","                plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","                plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","                plt.title(name)\n","#============================================== Testing =================================================================================================        \n","        GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = XGB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","        X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","        print('Running XGB ...')     \n","        clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=XGBClassifier() )   \n","            \n","        if USE_ALL_CLASSIFIERS :\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = DT_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running DT ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=DecisionTreeClassifier() )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = NB_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running NB ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=GaussianNB() )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number =RF_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running RF ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=RandomForestClassifier(n_estimators=100) )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = LR_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running LR ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=LogisticRegression(max_iter=1000) )   \n","\n","\n","            GAN_BOTS = generate_gan_data(REAL_BOTS, labels, weight_or_epoch_number = KNN_RCL_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = BENIGN_COUNTS - REAL_BOTS.shape[0])\n","            X_TEST, y_TEST = augment_bots_in_test_set(X_test, y_test, GAN_BOTS, training_data.columns)\n","            print('Running KNN ...')     \n","            clsfr_train_test(X_train, y_train, X_TEST, y_TEST, accu_list = GAN_aug_accu_list, rcl_list = GAN_aug_rcl_list, prec_list = GAN_aug_prec_list , f1_list = GAN_aug_f1_list, clf=KNeighborsClassifier(n_neighbors=5) )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-PossZBDWj2n"},"source":["<a id=\"DATA Generation for Others\"><h1>DATA GENERATION for Others</h1></a>"]},{"cell_type":"code","metadata":{"id":"aGXS6ieNWj2n"},"source":["if GENERATE_OTHERS_DATA:\n","    X_train = training_data[X_cols].values\n","    y_train = training_data[y_cols].values\n","    if GAN_type == 'CGAN' or GAN_type == 'WCGAN':\n","        df = REAL_BOTS.copy()\n","        DATA_SIZE = BENIGN_SAMPLES\n","\n","        for i in range (BENIGN_COUNTS//BOT_COUNTS):\n","            df = pd.concat([df, REAL_BOTS])\n","\n","        REAL_BOTS = df.copy()\n","        print(REAL_BOTS.shape)\n","        REAL_BOTS_WITHOUT_LABEL = REAL_BOTS[REAL_BOTS.columns[:-1]]      \n"," #============================================== Generate Labels =========================================================================================        \n","\n","        algorithms = [[ 'KMeans', cluster.KMeans, (), {'n_clusters':10, 'random_state':0} ],]\n","\n","        rows = len(algorithms)\n","        columns = 1\n","        fig, ax = plt.subplots(3, 2, figsize=(5, 3),\n","                                constrained_layout=True)\n","\n","        for i, [name, algorithm, args, kwds] in enumerate(algorithms):\n","\n","            labels = algorithm(*args, **kwds).fit_predict(REAL_BOTS_WITHOUT_LABEL)\n","            colors = np.clip(labels,-1,9)\n","            colors = [ 'C'+str(i) if i>-1 else 'white' for i in colors ]\n","\n","            plt.subplot(rows,columns,i*columns+1)\n","            plt.scatter(REAL_BOTS_WITHOUT_LABEL[X_cols[0]], REAL_BOTS_WITHOUT_LABEL[X_cols[1]], c=colors)\n","            plt.xlabel(X_cols[0]), plt.ylabel(X_cols[1])\n","            plt.title(name)\n","\n","    MALICIOUS_DATA = bots.copy() # Real Botnets\n","    \n","    print(MALICIOUS_DATA.shape)\n","\n","    WEIGHT = generate_gan_data(MALICIOUS_DATA, labels, weight_or_epoch_number = XGB_ACC_WEIGHT, data_dim = len(X_cols),  FULL_CACHE_PATH = CACHE_PATH,  GAN_type = GAN_type, TODAY = TODAY, DATA_SIZE = MALICIOUS_DATA.shape[0])\n","    augment_bots(X_train, y_train, WEIGHT, training_data.columns, GAN_type = GAN_type, DATA_SET_PATH = DATA_SET_PATH, classifier = DATA_SET)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-oepuFKWj2n"},"source":["training_data = pd.read_csv (DATA_SET + '_GAN_AUG_DATA_SET.csv', low_memory=False)\n","\n","print('Dataset Imported: ' + DATA_SET)\n","print('Training set: '+ str(training_data.shape))\n","\n","training_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7-YSdpfWj2o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fattbqdrWj2o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kJlZ9qh3Wj2o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzM7t1TIWj2q"},"source":[""],"execution_count":null,"outputs":[]}]}